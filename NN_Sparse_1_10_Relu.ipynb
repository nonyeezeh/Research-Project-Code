{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY+9vy0CsrLOwLZGAjwkXp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nonyeezeh/Research-Project-Code/blob/main/NN_Sparse_1_10_Relu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "FiyPwQVgg4kG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq3DL4WJgTG2",
        "outputId": "1f8c0c7e-3338-41ac-8bc4-9e12be773633",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pgmpy in /usr/local/lib/python3.10/dist-packages (0.1.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.1.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.1.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.4.1+cu121)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.14.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy) (4.66.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.4.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.3.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.1.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.7.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai->pgmpy) (1.24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost->pgmpy) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->pgmpy) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->pgmpy) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (4.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pgmpy) (1.16.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (4.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai->pgmpy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai->pgmpy) (2.23.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai->pgmpy) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai->pgmpy) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->pgmpy) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install pgmpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.sampling import BayesianModelSampling\n",
        "from tabulate import tabulate\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models, layers, callbacks, regularizers\n",
        "\n",
        "from scipy.stats import entropy"
      ],
      "metadata": {
        "id": "dD18R7PRg8lH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Network Data Generation 1000, 2000, ..., 10000 Samples (sparse)"
      ],
      "metadata": {
        "id": "H2dmo6j0g-DM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate CPDs for a Sparse BN with random relationships\n",
        "def generate_sparse_cpds():\n",
        "    # Generate random probabilities for IR\n",
        "    ir_probs = np.random.rand(3)\n",
        "    ir_probs /= ir_probs.sum()  # Normalize to make it a valid probability distribution\n",
        "\n",
        "    # Generate random probabilities for EI\n",
        "    ei_probs = np.random.rand(3)\n",
        "    ei_probs /= ei_probs.sum()  # Normalize to make it a valid probability distribution\n",
        "\n",
        "    # Generate random probabilities for SP, either given IR, EI, or both, randomly chosen\n",
        "    relationship = np.random.choice(['IR', 'EI', 'IR_EI'])\n",
        "\n",
        "    if relationship == 'IR':\n",
        "        # SP depends only on IR\n",
        "        sp_probs = np.random.rand(3, 3)\n",
        "        sp_probs /= sp_probs.sum(axis=0, keepdims=True)\n",
        "        return ir_probs, ei_probs, sp_probs, 'IR'\n",
        "\n",
        "    elif relationship == 'EI':\n",
        "        # SP depends only on EI\n",
        "        sp_probs = np.random.rand(3, 3)\n",
        "        sp_probs /= sp_probs.sum(axis=0, keepdims=True)\n",
        "        return ir_probs, ei_probs, sp_probs, 'EI'\n",
        "\n",
        "    else:\n",
        "        # SP depends on both IR and EI\n",
        "        sp_probs = np.random.rand(3, 3, 3)\n",
        "        sp_probs /= sp_probs.sum(axis=0, keepdims=True)\n",
        "        return ir_probs, ei_probs, sp_probs, 'IR_EI'\n",
        "\n",
        "# Function to generate and save samples for Sparse BN\n",
        "def generate_and_save_sparse_samples(ir_probs, ei_probs, sp_probs, relationship, sample_size, filename):\n",
        "    output_data = []\n",
        "\n",
        "    # Generate `sample_size` random samples\n",
        "    for _ in range(sample_size):\n",
        "        # Sample `IR` state based on `IR` probabilities\n",
        "        ir_state_idx = np.random.choice(3, p=ir_probs)\n",
        "        ir_state = ['low', 'medium', 'high'][ir_state_idx]\n",
        "        ir_prob = ir_probs[ir_state_idx]\n",
        "\n",
        "        # Sample `EI` state based on `EI` probabilities\n",
        "        ei_state_idx = np.random.choice(3, p=ei_probs)\n",
        "        ei_state = ['poor', 'average', 'good'][ei_state_idx]\n",
        "        ei_prob = ei_probs[ei_state_idx]\n",
        "\n",
        "        # Sample `SP` state based on the random relationship\n",
        "        if relationship == 'IR':\n",
        "            # SP depends only on IR\n",
        "            sp_probs_given_ir = sp_probs[:, ir_state_idx]\n",
        "            sp_state_idx = np.random.choice(3, p=sp_probs_given_ir)\n",
        "            sp_state = ['decrease', 'stable', 'increase'][sp_state_idx]\n",
        "            sp_prob = sp_probs_given_ir[sp_state_idx]\n",
        "\n",
        "        elif relationship == 'EI':\n",
        "            # SP depends only on EI\n",
        "            sp_probs_given_ei = sp_probs[:, ei_state_idx]\n",
        "            sp_state_idx = np.random.choice(3, p=sp_probs_given_ei)\n",
        "            sp_state = ['decrease', 'stable', 'increase'][sp_state_idx]\n",
        "            sp_prob = sp_probs_given_ei[sp_state_idx]\n",
        "\n",
        "        else:\n",
        "            # SP depends on both IR and EI\n",
        "            sp_probs_given_ir_ei = sp_probs[:, ir_state_idx, ei_state_idx]\n",
        "            sp_state_idx = np.random.choice(3, p=sp_probs_given_ir_ei)\n",
        "            sp_state = ['decrease', 'stable', 'increase'][sp_state_idx]\n",
        "            sp_prob = sp_probs_given_ir_ei[sp_state_idx]\n",
        "\n",
        "        # Append sample data to output list\n",
        "        output_data.append({\n",
        "            'IR_State': ir_state,\n",
        "            'IR_Prob': f'{ir_prob:.4f}',\n",
        "            'EI_State': ei_state,\n",
        "            'EI_Prob': f'{ei_prob:.4f}',\n",
        "            'SP_Probabilities (decrease, stable, increase)': ', '.join([f'{prob:.4f}' for prob in (\n",
        "              sp_probs_given_ir_ei if relationship == 'IR_EI' else\n",
        "              sp_probs_given_ir if relationship == 'IR' else\n",
        "              sp_probs_given_ei\n",
        "            )]),\n",
        "            'Chosen_SP_State': sp_state,\n",
        "            'Chosen_SP_Probability': f'{sp_prob:.4f}',\n",
        "            'Relationship': relationship\n",
        "        })\n",
        "\n",
        "    # Create a DataFrame from the output data\n",
        "    output_df = pd.DataFrame(output_data)\n",
        "\n",
        "    # Save the output DataFrame to a CSV file\n",
        "    output_df.to_csv(filename, index=False)\n",
        "\n",
        "    # Print the first few rows for visual confirmation\n",
        "    print(f\"\\nSample size: {sample_size} - First few rows of generated samples:\\n\")\n",
        "    print(tabulate(output_df.head(), headers='keys', tablefmt='grid'))\n",
        "\n",
        "# Generate and save samples for sample sizes from 1000 to 10000 every 1000 for Sparse BN\n",
        "sample_sizes = range(1000, 11000, 1000)\n",
        "\n",
        "for size in sample_sizes:\n",
        "    # Generate the CPDs for Sparse BN\n",
        "    ir_probs, ei_probs, sp_probs, relationship = generate_sparse_cpds()\n",
        "\n",
        "    # Generate and save individual samples for the given sample size\n",
        "    generate_and_save_sparse_samples(ir_probs, ei_probs, sp_probs, relationship, size, f'combined_sparse_probabilities_{size}.csv')\n",
        "\n",
        "# Notify the user that the process is done\n",
        "print(\"\\nGeneration and saving of individual samples complete for all sample sizes (Sparse BN)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHon-SJqhB1Y",
        "outputId": "7ffa56ad-9365-43fe-d4c1-14a9d0e6cdf7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 1000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability | Relationship   |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+================+\n",
            "|  0 | low        |    0.2781 | good       |    0.4104 | 0.2038, 0.0124, 0.7838                          | increase          |                  0.7838 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  1 | high       |    0.3065 | poor       |    0.5134 | 0.2999, 0.4257, 0.2745                          | increase          |                  0.2745 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  2 | high       |    0.3065 | poor       |    0.5134 | 0.2999, 0.4257, 0.2745                          | stable            |                  0.4257 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  3 | low        |    0.2781 | poor       |    0.5134 | 0.2999, 0.4257, 0.2745                          | decrease          |                  0.2999 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  4 | low        |    0.2781 | good       |    0.4104 | 0.2038, 0.0124, 0.7838                          | increase          |                  0.7838 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "\n",
            "Sample size: 2000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability | Relationship   |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+================+\n",
            "|  0 | high       |    0.7076 | average    |    0.3447 | 0.1044, 0.5427, 0.3528                          | increase          |                  0.3528 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  1 | high       |    0.7076 | average    |    0.3447 | 0.1044, 0.5427, 0.3528                          | stable            |                  0.5427 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  2 | high       |    0.7076 | good       |    0.6309 | 0.3954, 0.2537, 0.3509                          | stable            |                  0.2537 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  3 | high       |    0.7076 | good       |    0.6309 | 0.3954, 0.2537, 0.3509                          | increase          |                  0.3509 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  4 | low        |    0.2821 | average    |    0.3447 | 0.1293, 0.5495, 0.3212                          | stable            |                  0.5495 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "\n",
            "Sample size: 3000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability | Relationship   |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+================+\n",
            "|  0 | low        |    0.4586 | good       |    0.8133 | 0.6984, 0.0007, 0.3009                          | increase          |                  0.3009 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  1 | high       |    0.3626 | good       |    0.8133 | 0.4256, 0.1663, 0.4081                          | increase          |                  0.4081 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  2 | high       |    0.3626 | good       |    0.8133 | 0.4256, 0.1663, 0.4081                          | increase          |                  0.4081 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  3 | high       |    0.3626 | good       |    0.8133 | 0.4256, 0.1663, 0.4081                          | decrease          |                  0.4256 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  4 | high       |    0.3626 | good       |    0.8133 | 0.4256, 0.1663, 0.4081                          | decrease          |                  0.4256 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "\n",
            "Sample size: 4000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability | Relationship   |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+================+\n",
            "|  0 | low        |    0.6498 | good       |    0.619  | 0.2538, 0.0448, 0.7015                          | increase          |                  0.7015 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  1 | low        |    0.6498 | average    |    0.1214 | 0.4009, 0.1707, 0.4284                          | increase          |                  0.4284 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  2 | low        |    0.6498 | average    |    0.1214 | 0.4009, 0.1707, 0.4284                          | increase          |                  0.4284 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  3 | low        |    0.6498 | poor       |    0.2597 | 0.3546, 0.1665, 0.4788                          | increase          |                  0.4788 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  4 | high       |    0.2902 | poor       |    0.2597 | 0.3546, 0.1665, 0.4788                          | increase          |                  0.4788 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "\n",
            "Sample size: 5000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability | Relationship   |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+================+\n",
            "|  0 | low        |    0.4515 | average    |    0.411  | 0.4429, 0.0031, 0.5540                          | decrease          |                  0.4429 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  1 | medium     |    0.3299 | good       |    0.2586 | 0.5215, 0.3015, 0.1770                          | decrease          |                  0.5215 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  2 | low        |    0.4515 | good       |    0.2586 | 0.4409, 0.2801, 0.2791                          | increase          |                  0.2791 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  3 | low        |    0.4515 | good       |    0.2586 | 0.4409, 0.2801, 0.2791                          | increase          |                  0.2791 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  4 | medium     |    0.3299 | average    |    0.411  | 0.2795, 0.4996, 0.2209                          | decrease          |                  0.2795 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "\n",
            "Sample size: 6000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability | Relationship   |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+================+\n",
            "|  0 | high       |    0.3053 | average    |    0.5617 | 0.3297, 0.4740, 0.1963                          | stable            |                  0.474  | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  1 | low        |    0.5477 | average    |    0.5617 | 0.3297, 0.4740, 0.1963                          | decrease          |                  0.3297 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  2 | high       |    0.3053 | good       |    0.3476 | 0.2484, 0.2901, 0.4615                          | stable            |                  0.2901 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  3 | medium     |    0.1469 | good       |    0.3476 | 0.2484, 0.2901, 0.4615                          | stable            |                  0.2901 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  4 | low        |    0.5477 | average    |    0.5617 | 0.3297, 0.4740, 0.1963                          | decrease          |                  0.3297 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "\n",
            "Sample size: 7000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability | Relationship   |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+================+\n",
            "|  0 | high       |    0.7297 | good       |    0.3319 | 0.5111, 0.1512, 0.3377                          | increase          |                  0.3377 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  1 | high       |    0.7297 | poor       |    0.2575 | 0.8672, 0.0587, 0.0742                          | decrease          |                  0.8672 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  2 | high       |    0.7297 | average    |    0.4106 | 0.2737, 0.4721, 0.2542                          | decrease          |                  0.2737 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  3 | medium     |    0.2152 | good       |    0.3319 | 0.4881, 0.3118, 0.2001                          | decrease          |                  0.4881 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  4 | high       |    0.7297 | good       |    0.3319 | 0.5111, 0.1512, 0.3377                          | increase          |                  0.3377 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "\n",
            "Sample size: 8000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability | Relationship   |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+================+\n",
            "|  0 | low        |    0.426  | good       |    0.2889 | 0.3866, 0.5983, 0.0150                          | decrease          |                  0.3866 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  1 | high       |    0.5038 | average    |    0.4386 | 0.1607, 0.2083, 0.6310                          | increase          |                  0.631  | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  2 | high       |    0.5038 | average    |    0.4386 | 0.1607, 0.2083, 0.6310                          | increase          |                  0.631  | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  3 | low        |    0.426  | average    |    0.4386 | 0.1607, 0.2083, 0.6310                          | increase          |                  0.631  | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  4 | low        |    0.426  | good       |    0.2889 | 0.3866, 0.5983, 0.0150                          | decrease          |                  0.3866 | EI             |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "\n",
            "Sample size: 9000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability | Relationship   |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+================+\n",
            "|  0 | low        |    0.2517 | poor       |    0.5423 | 0.3793, 0.1511, 0.4696                          | increase          |                  0.4696 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  1 | high       |    0.4017 | good       |    0.4085 | 0.0771, 0.0642, 0.8587                          | stable            |                  0.0642 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  2 | low        |    0.2517 | average    |    0.0492 | 0.2088, 0.3831, 0.4081                          | increase          |                  0.4081 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  3 | low        |    0.2517 | poor       |    0.5423 | 0.3793, 0.1511, 0.4696                          | decrease          |                  0.3793 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  4 | low        |    0.2517 | good       |    0.4085 | 0.3893, 0.0267, 0.5840                          | increase          |                  0.584  | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "\n",
            "Sample size: 10000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability | Relationship   |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+================+\n",
            "|  0 | low        |    0.3642 | poor       |    0.6133 | 0.4131, 0.3184, 0.2685                          | decrease          |                  0.4131 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  1 | low        |    0.3642 | poor       |    0.6133 | 0.4131, 0.3184, 0.2685                          | decrease          |                  0.4131 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  2 | high       |    0.5026 | poor       |    0.6133 | 0.3623, 0.2346, 0.4030                          | increase          |                  0.403  | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  3 | high       |    0.5026 | good       |    0.2368 | 0.2360, 0.1108, 0.6533                          | increase          |                  0.6533 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "|  4 | low        |    0.3642 | poor       |    0.6133 | 0.4131, 0.3184, 0.2685                          | stable            |                  0.3184 | IR_EI          |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+----------------+\n",
            "\n",
            "Generation and saving of individual samples complete for all sample sizes (Sparse BN)!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypothesis Model 1000, 2000, ..., 10000 Samples (sparse) 1 hidden Layer, 10 Neurons Relu"
      ],
      "metadata": {
        "id": "eBg421mchP7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sizes to loop through\n",
        "sample_sizes = range(1000, 11000, 1000)\n",
        "\n",
        "# Define the Neural Network architecture with L2 regularization\n",
        "def create_nn_model(input_shape, hidden_layers=1, nodes_per_layer=10, l2_lambda=0.01):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Input layer with dynamic input shape (1 or 2 features)\n",
        "    model.add(layers.InputLayer(input_shape=(input_shape,)))\n",
        "\n",
        "    # Hidden layers with L2 regularization and Dropout\n",
        "    for layer_num in range(hidden_layers):\n",
        "        model.add(layers.Dense(\n",
        "            nodes_per_layer,\n",
        "            activation='relu',\n",
        "            kernel_regularizer=regularizers.l2(l2_lambda),  # L2 regularization\n",
        "            name=f\"hidden_layer_{layer_num + 1}\"\n",
        "        ))\n",
        "        model.add(layers.Dropout(0.2))  # Dropout layer to reduce overfitting\n",
        "\n",
        "    # Output layer (3 classes: decrease, stable, increase) with L2 regularization\n",
        "    model.add(layers.Dense(\n",
        "        3,\n",
        "        activation='softmax',\n",
        "        kernel_regularizer=regularizers.l2(l2_lambda),  # L2 regularization\n",
        "        name=\"output_layer\"\n",
        "    ))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Prepare a dictionary to store the extracted data for each sample size\n",
        "extracted_data = {}\n",
        "\n",
        "# Extract the required columns from all sample sizes first\n",
        "for size in sample_sizes:\n",
        "    # Load data for the current sample size (adjust the file paths if necessary)\n",
        "    outcomes_file = f'combined_sparse_probabilities_{size}.csv'\n",
        "    df = pd.read_csv(outcomes_file)\n",
        "\n",
        "    # Extract columns based on relationship\n",
        "    relationship = df['Relationship'][0]  # Assuming all rows have the same relationship in this sample\n",
        "\n",
        "    # Determine which columns to extract based on relationship\n",
        "    if relationship == 'IR EI':\n",
        "        required_columns = ['IR_State', 'EI_State', 'Chosen_SP_State']\n",
        "    elif relationship == 'IR':\n",
        "        required_columns = ['IR_State', 'Chosen_SP_State']\n",
        "    elif relationship == 'EI':\n",
        "        required_columns = ['EI_State', 'Chosen_SP_State']\n",
        "\n",
        "    df_extracted = df[required_columns]\n",
        "\n",
        "    # Manually encode categorical variables for IR, EI, and SP\n",
        "    ir_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "    ei_map = {'poor': 0, 'average': 1, 'good': 2}\n",
        "    sp_map = {'decrease': 0, 'stable': 1, 'increase': 2}\n",
        "\n",
        "    if 'IR_State' in df_extracted.columns:\n",
        "        df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
        "    if 'EI_State' in df_extracted.columns:\n",
        "        df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
        "    df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
        "\n",
        "    # Store the extracted and encoded data for later use\n",
        "    extracted_data[size] = df_extracted\n",
        "\n",
        "# Loop through each sample size for NN training, validation, and testing\n",
        "for size in sample_sizes:\n",
        "    # Retrieve the extracted data for the current sample size\n",
        "    df = extracted_data[size]\n",
        "\n",
        "    # Determine features (X) and labels (y) based on available columns\n",
        "    if 'IR_encoded' in df.columns and 'EI_encoded' in df.columns:\n",
        "        X = df[['IR_encoded', 'EI_encoded']]\n",
        "    elif 'IR_encoded' in df.columns:\n",
        "        X = df[['IR_encoded']]\n",
        "    elif 'EI_encoded' in df.columns:\n",
        "        X = df[['EI_encoded']]\n",
        "\n",
        "    y = df['SP_encoded']\n",
        "\n",
        "    # Refresh the data split for each iteration\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False, random_state=42)\n",
        "\n",
        "    # Show split confirmation\n",
        "    print(f\"\\nSample size: {size}\")\n",
        "    print(\"Training Data:\", X_train.shape, y_train.shape)\n",
        "    print(\"Validation Data:\", X_val.shape, y_val.shape)\n",
        "    print(\"Test Data:\", X_test.shape, y_test.shape)\n",
        "\n",
        "    # Create the Neural Network model with L2 regularization\n",
        "    input_shape = X_train.shape[1]  # Number of features (1 or 2)\n",
        "    nn_model = create_nn_model(input_shape=input_shape, hidden_layers=1, nodes_per_layer=10, l2_lambda=0.01)\n",
        "\n",
        "    # Early stopping callback to prevent overfitting\n",
        "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    history = nn_model.fit(X_train, y_train,\n",
        "                           epochs=50,\n",
        "                           batch_size=32,\n",
        "                           validation_data=(X_val, y_val),\n",
        "                           callbacks=[early_stopping],\n",
        "                           verbose=0)  # Set verbose=0 to avoid too much output\n",
        "\n",
        "    # Print training, validation, and test accuracy\n",
        "    train_loss, train_accuracy = nn_model.evaluate(X_train, y_train, verbose=0)\n",
        "    val_loss, val_accuracy = nn_model.evaluate(X_val, y_val, verbose=0)\n",
        "    test_loss, test_accuracy = nn_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"Training Accuracy for {size} samples: {train_accuracy:.4f}\")\n",
        "    print(f\"Validation Accuracy for {size} samples: {val_accuracy:.4f}\")\n",
        "    print(f\"Test Accuracy for {size} samples: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    predictions = nn_model.predict(X_test)\n",
        "\n",
        "    # Convert the predicted probabilities to class labels\n",
        "    predicted_classes = predictions.argmax(axis=1)\n",
        "\n",
        "    # Create a list to map integers back to the original SP labels\n",
        "    sp_reverse_map = ['decrease', 'stable', 'increase']\n",
        "\n",
        "    # Convert the predicted classes to the original labels\n",
        "    predicted_labels = [sp_reverse_map[label] for label in predicted_classes]\n",
        "\n",
        "    # Create a DataFrame for the predicted probabilities\n",
        "    probs_df = pd.DataFrame(predictions, columns=['Prob_decrease', 'Prob_stable', 'Prob_increase'])\n",
        "\n",
        "    # Output the features, predicted SP, and the NN probabilities\n",
        "    result_df = X_test.copy()\n",
        "    result_df['Predicted_SP'] = predicted_labels\n",
        "\n",
        "    # Combine the result with the predicted probabilities\n",
        "    combined_df = pd.concat([result_df.reset_index(drop=True), probs_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    # Save the test data with predictions to a CSV file\n",
        "    combined_df.to_csv(f'test_data_nn_sparse_{size}.csv', index=False)\n",
        "\n",
        "    # Show the first few rows of the results for this sample size\n",
        "    print(f\"\\nPredicted Results and Probabilities for {size} samples (First 15 rows):\")\n",
        "    print(combined_df.head(15))\n",
        "\n",
        "# After the loop is done, print this message\n",
        "print(\"\\nLooping through all sample sizes complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYPvkkfDhVDN",
        "outputId": "be34eaf9-5484-40bd-83c1-bf6a0670e20a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-7bea497a529a>:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-11-7bea497a529a>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-11-7bea497a529a>:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-11-7bea497a529a>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-11-7bea497a529a>:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-11-7bea497a529a>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-11-7bea497a529a>:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-11-7bea497a529a>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-11-7bea497a529a>:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-11-7bea497a529a>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-11-7bea497a529a>:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-11-7bea497a529a>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-11-7bea497a529a>:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-11-7bea497a529a>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-11-7bea497a529a>:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-11-7bea497a529a>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-11-7bea497a529a>:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-11-7bea497a529a>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-11-7bea497a529a>:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-11-7bea497a529a>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 1000\n",
            "Training Data: (700, 1) (700,)\n",
            "Validation Data: (150, 1) (150,)\n",
            "Test Data: (150, 1) (150,)\n",
            "Training Accuracy for 1000 samples: 0.5657\n",
            "Validation Accuracy for 1000 samples: 0.6000\n",
            "Test Accuracy for 1000 samples: 0.6200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "\n",
            "Predicted Results and Probabilities for 1000 samples (First 15 rows):\n",
            "    EI_encoded Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0            2     increase       0.227285     0.058955       0.713760\n",
            "1            2     increase       0.227285     0.058955       0.713760\n",
            "2            0       stable       0.315123     0.343918       0.340959\n",
            "3            2     increase       0.227285     0.058955       0.713760\n",
            "4            2     increase       0.227285     0.058955       0.713760\n",
            "5            0       stable       0.315123     0.343918       0.340959\n",
            "6            0       stable       0.315123     0.343918       0.340959\n",
            "7            0       stable       0.315123     0.343918       0.340959\n",
            "8            0       stable       0.315123     0.343918       0.340959\n",
            "9            0       stable       0.315123     0.343918       0.340959\n",
            "10           0       stable       0.315123     0.343918       0.340959\n",
            "11           2     increase       0.227285     0.058955       0.713760\n",
            "12           0       stable       0.315123     0.343918       0.340959\n",
            "13           0       stable       0.315123     0.343918       0.340959\n",
            "14           0       stable       0.315123     0.343918       0.340959\n",
            "\n",
            "Sample size: 2000\n",
            "Training Data: (1400, 1) (1400,)\n",
            "Validation Data: (300, 1) (300,)\n",
            "Test Data: (300, 1) (300,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 2000 samples: 0.4464\n",
            "Validation Accuracy for 2000 samples: 0.3833\n",
            "Test Accuracy for 2000 samples: 0.4467\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\n",
            "Predicted Results and Probabilities for 2000 samples (First 15 rows):\n",
            "    EI_encoded Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0            1       stable       0.214768     0.420133       0.365099\n",
            "1            2     decrease       0.373663     0.254343       0.371994\n",
            "2            2     decrease       0.373663     0.254343       0.371994\n",
            "3            2     decrease       0.373663     0.254343       0.371994\n",
            "4            1       stable       0.214768     0.420133       0.365099\n",
            "5            2     decrease       0.373663     0.254343       0.371994\n",
            "6            1       stable       0.214768     0.420133       0.365099\n",
            "7            1       stable       0.214768     0.420133       0.365099\n",
            "8            1       stable       0.214768     0.420133       0.365099\n",
            "9            2     decrease       0.373663     0.254343       0.371994\n",
            "10           2     decrease       0.373663     0.254343       0.371994\n",
            "11           1       stable       0.214768     0.420133       0.365099\n",
            "12           2     decrease       0.373663     0.254343       0.371994\n",
            "13           1       stable       0.214768     0.420133       0.365099\n",
            "14           0       stable       0.213910     0.427714       0.358376\n",
            "\n",
            "Sample size: 3000\n",
            "Training Data: (2100, 1) (2100,)\n",
            "Validation Data: (450, 1) (450,)\n",
            "Test Data: (450, 1) (450,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 3000 samples: 0.5462\n",
            "Validation Accuracy for 3000 samples: 0.5489\n",
            "Test Accuracy for 3000 samples: 0.5800\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\n",
            "Predicted Results and Probabilities for 3000 samples (First 15 rows):\n",
            "    EI_encoded Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0            2     decrease       0.553515     0.141406       0.305078\n",
            "1            2     decrease       0.553515     0.141406       0.305078\n",
            "2            2     decrease       0.553515     0.141406       0.305078\n",
            "3            2     decrease       0.553515     0.141406       0.305078\n",
            "4            1     decrease       0.513597     0.176014       0.310389\n",
            "5            2     decrease       0.553515     0.141406       0.305078\n",
            "6            2     decrease       0.553515     0.141406       0.305078\n",
            "7            2     decrease       0.553515     0.141406       0.305078\n",
            "8            2     decrease       0.553515     0.141406       0.305078\n",
            "9            2     decrease       0.553515     0.141406       0.305078\n",
            "10           2     decrease       0.553515     0.141406       0.305078\n",
            "11           2     decrease       0.553515     0.141406       0.305078\n",
            "12           2     decrease       0.553515     0.141406       0.305078\n",
            "13           1     decrease       0.513597     0.176014       0.310389\n",
            "14           2     decrease       0.553515     0.141406       0.305078\n",
            "\n",
            "Sample size: 4000\n",
            "Training Data: (2800, 1) (2800,)\n",
            "Validation Data: (600, 1) (600,)\n",
            "Test Data: (600, 1) (600,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 4000 samples: 0.6064\n",
            "Validation Accuracy for 4000 samples: 0.5967\n",
            "Test Accuracy for 4000 samples: 0.6283\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 4000 samples (First 15 rows):\n",
            "    EI_encoded Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0            2     increase       0.269514     0.064917       0.665569\n",
            "1            2     increase       0.269514     0.064917       0.665569\n",
            "2            2     increase       0.269514     0.064917       0.665569\n",
            "3            1     increase       0.312148     0.110883       0.576970\n",
            "4            2     increase       0.269514     0.064917       0.665569\n",
            "5            0     increase       0.343954     0.180191       0.475855\n",
            "6            2     increase       0.269514     0.064917       0.665569\n",
            "7            0     increase       0.343954     0.180191       0.475855\n",
            "8            2     increase       0.269514     0.064917       0.665569\n",
            "9            2     increase       0.269514     0.064917       0.665569\n",
            "10           1     increase       0.312148     0.110883       0.576970\n",
            "11           2     increase       0.269514     0.064917       0.665569\n",
            "12           0     increase       0.343954     0.180191       0.475855\n",
            "13           2     increase       0.269514     0.064917       0.665569\n",
            "14           0     increase       0.343954     0.180191       0.475855\n",
            "\n",
            "Sample size: 5000\n",
            "Training Data: (3500, 1) (3500,)\n",
            "Validation Data: (750, 1) (750,)\n",
            "Test Data: (750, 1) (750,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 5000 samples: 0.4020\n",
            "Validation Accuracy for 5000 samples: 0.4000\n",
            "Test Accuracy for 5000 samples: 0.3907\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 5000 samples (First 15 rows):\n",
            "    EI_encoded Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0            1     decrease       0.404671     0.280453       0.314876\n",
            "1            0     decrease       0.379760     0.252734       0.367506\n",
            "2            2     decrease       0.426189     0.307691       0.266120\n",
            "3            2     decrease       0.426189     0.307691       0.266120\n",
            "4            1     decrease       0.404671     0.280453       0.314876\n",
            "5            2     decrease       0.426189     0.307691       0.266120\n",
            "6            0     decrease       0.379760     0.252734       0.367506\n",
            "7            2     decrease       0.426189     0.307691       0.266120\n",
            "8            1     decrease       0.404671     0.280453       0.314876\n",
            "9            2     decrease       0.426189     0.307691       0.266120\n",
            "10           1     decrease       0.404671     0.280453       0.314876\n",
            "11           1     decrease       0.404671     0.280453       0.314876\n",
            "12           1     decrease       0.404671     0.280453       0.314876\n",
            "13           0     decrease       0.379760     0.252734       0.367506\n",
            "14           1     decrease       0.404671     0.280453       0.314876\n",
            "\n",
            "Sample size: 6000\n",
            "Training Data: (4200, 1) (4200,)\n",
            "Validation Data: (900, 1) (900,)\n",
            "Test Data: (900, 1) (900,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 6000 samples: 0.4579\n",
            "Validation Accuracy for 6000 samples: 0.4589\n",
            "Test Accuracy for 6000 samples: 0.4267\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 6000 samples (First 15 rows):\n",
            "    EI_encoded Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0            2     increase       0.274055     0.334281       0.391664\n",
            "1            1       stable       0.311223     0.432358       0.256419\n",
            "2            1       stable       0.311223     0.432358       0.256419\n",
            "3            2     increase       0.274055     0.334281       0.391664\n",
            "4            1       stable       0.311223     0.432358       0.256419\n",
            "5            2     increase       0.274055     0.334281       0.391664\n",
            "6            2     increase       0.274055     0.334281       0.391664\n",
            "7            1       stable       0.311223     0.432358       0.256419\n",
            "8            2     increase       0.274055     0.334281       0.391664\n",
            "9            2     increase       0.274055     0.334281       0.391664\n",
            "10           1       stable       0.311223     0.432358       0.256419\n",
            "11           1       stable       0.311223     0.432358       0.256419\n",
            "12           2     increase       0.274055     0.334281       0.391664\n",
            "13           1       stable       0.311223     0.432358       0.256419\n",
            "14           2     increase       0.274055     0.334281       0.391664\n",
            "\n",
            "Sample size: 7000\n",
            "Training Data: (4900, 1) (4900,)\n",
            "Validation Data: (1050, 1) (1050,)\n",
            "Test Data: (1050, 1) (1050,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 7000 samples: 0.4484\n",
            "Validation Accuracy for 7000 samples: 0.4771\n",
            "Test Accuracy for 7000 samples: 0.4629\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 7000 samples (First 15 rows):\n",
            "    EI_encoded Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0            2     decrease       0.436541     0.245614       0.317845\n",
            "1            1     decrease       0.388755     0.320627       0.290619\n",
            "2            0     decrease       0.570345     0.197723       0.231932\n",
            "3            2     decrease       0.436541     0.245614       0.317845\n",
            "4            1     decrease       0.388755     0.320627       0.290619\n",
            "5            1     decrease       0.388755     0.320627       0.290619\n",
            "6            0     decrease       0.570345     0.197723       0.231932\n",
            "7            2     decrease       0.436541     0.245614       0.317845\n",
            "8            1     decrease       0.388755     0.320627       0.290619\n",
            "9            1     decrease       0.388755     0.320627       0.290619\n",
            "10           0     decrease       0.570345     0.197723       0.231932\n",
            "11           2     decrease       0.436541     0.245614       0.317845\n",
            "12           1     decrease       0.388755     0.320627       0.290619\n",
            "13           2     decrease       0.436541     0.245614       0.317845\n",
            "14           2     decrease       0.436541     0.245614       0.317845\n",
            "\n",
            "Sample size: 8000\n",
            "Training Data: (5600, 1) (5600,)\n",
            "Validation Data: (1200, 1) (1200,)\n",
            "Test Data: (1200, 1) (1200,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 8000 samples: 0.6166\n",
            "Validation Accuracy for 8000 samples: 0.6400\n",
            "Test Accuracy for 8000 samples: 0.6100\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 8000 samples (First 15 rows):\n",
            "    EI_encoded Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0            2       stable       0.329749     0.543725       0.126527\n",
            "1            1     increase       0.170152     0.270396       0.559453\n",
            "2            2       stable       0.329749     0.543725       0.126527\n",
            "3            1     increase       0.170152     0.270396       0.559453\n",
            "4            0     increase       0.170018     0.270176       0.559806\n",
            "5            0     increase       0.170018     0.270176       0.559806\n",
            "6            1     increase       0.170152     0.270396       0.559453\n",
            "7            1     increase       0.170152     0.270396       0.559453\n",
            "8            1     increase       0.170152     0.270396       0.559453\n",
            "9            2       stable       0.329749     0.543725       0.126527\n",
            "10           2       stable       0.329749     0.543725       0.126527\n",
            "11           1     increase       0.170152     0.270396       0.559453\n",
            "12           1     increase       0.170152     0.270396       0.559453\n",
            "13           2       stable       0.329749     0.543725       0.126527\n",
            "14           0     increase       0.170018     0.270176       0.559806\n",
            "\n",
            "Sample size: 9000\n",
            "Training Data: (6300, 1) (6300,)\n",
            "Validation Data: (1350, 1) (1350,)\n",
            "Test Data: (1350, 1) (1350,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 9000 samples: 0.5054\n",
            "Validation Accuracy for 9000 samples: 0.5504\n",
            "Test Accuracy for 9000 samples: 0.5148\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 9000 samples (First 15 rows):\n",
            "    EI_encoded Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0            0       stable       0.306623     0.375105       0.318272\n",
            "1            2     increase       0.240399     0.094810       0.664791\n",
            "2            1     increase       0.295122     0.205227       0.499651\n",
            "3            0       stable       0.306623     0.375105       0.318272\n",
            "4            0       stable       0.306623     0.375105       0.318272\n",
            "5            2     increase       0.240399     0.094810       0.664791\n",
            "6            2     increase       0.240399     0.094810       0.664791\n",
            "7            2     increase       0.240399     0.094810       0.664791\n",
            "8            0       stable       0.306623     0.375105       0.318272\n",
            "9            2     increase       0.240399     0.094810       0.664791\n",
            "10           2     increase       0.240399     0.094810       0.664791\n",
            "11           2     increase       0.240399     0.094810       0.664791\n",
            "12           2     increase       0.240399     0.094810       0.664791\n",
            "13           0       stable       0.306623     0.375105       0.318272\n",
            "14           0       stable       0.306623     0.375105       0.318272\n",
            "\n",
            "Sample size: 10000\n",
            "Training Data: (7000, 1) (7000,)\n",
            "Validation Data: (1500, 1) (1500,)\n",
            "Test Data: (1500, 1) (1500,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 10000 samples: 0.4319\n",
            "Validation Accuracy for 10000 samples: 0.4220\n",
            "Test Accuracy for 10000 samples: 0.4207\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 10000 samples (First 15 rows):\n",
            "    EI_encoded Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0            0     decrease       0.403512     0.247152       0.349336\n",
            "1            0     decrease       0.403512     0.247152       0.349336\n",
            "2            1     decrease       0.399375     0.237575       0.363051\n",
            "3            0     decrease       0.403512     0.247152       0.349336\n",
            "4            2     increase       0.379497     0.224927       0.395576\n",
            "5            0     decrease       0.403512     0.247152       0.349336\n",
            "6            2     increase       0.379497     0.224927       0.395576\n",
            "7            2     increase       0.379497     0.224927       0.395576\n",
            "8            2     increase       0.379497     0.224927       0.395576\n",
            "9            0     decrease       0.403512     0.247152       0.349336\n",
            "10           0     decrease       0.403512     0.247152       0.349336\n",
            "11           0     decrease       0.403512     0.247152       0.349336\n",
            "12           1     decrease       0.399375     0.237575       0.363051\n",
            "13           0     decrease       0.403512     0.247152       0.349336\n",
            "14           2     increase       0.379497     0.224927       0.395576\n",
            "\n",
            "Looping through all sample sizes complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-L Divergence NN Sparse Data"
      ],
      "metadata": {
        "id": "c6aZlRLhhZva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sizes to loop through\n",
        "sample_sizes = range(1000, 11000, 1000)\n",
        "\n",
        "# Prepare a list to store K-L divergence results\n",
        "kl_divergence_results = []\n",
        "\n",
        "# Loop through each sample size\n",
        "for size in sample_sizes:\n",
        "    print(f\"\\nProcessing sample size: {size}\")\n",
        "\n",
        "    # Load the combined BN data for the current sample size\n",
        "    combined_data_bn = pd.read_csv(f'combined_sparse_probabilities_{size}.csv')\n",
        "\n",
        "    # Determine features to use based on available columns\n",
        "    if 'IR_State' in combined_data_bn.columns and 'EI_State' in combined_data_bn.columns:\n",
        "        X = combined_data_bn[['IR_State', 'EI_State']]\n",
        "    elif 'IR_State' in combined_data_bn.columns:\n",
        "        X = combined_data_bn[['IR_State']]\n",
        "    elif 'EI_State' in combined_data_bn.columns:\n",
        "        X = combined_data_bn[['EI_State']]\n",
        "    else:\n",
        "        raise ValueError(\"No features available for training.\")\n",
        "\n",
        "    # Define labels (SP) and its probabilities\n",
        "    y = combined_data_bn[['Chosen_SP_State', 'SP_Probabilities (decrease, stable, increase)']]\n",
        "\n",
        "    # Refresh the data split for each iteration\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False, random_state=42)\n",
        "\n",
        "    # Get the test indices\n",
        "    test_indices = X_test.index\n",
        "\n",
        "    # Get the corresponding rows from the combined BN data using the test indices\n",
        "    bn_test_data = combined_data_bn.loc[test_indices]\n",
        "\n",
        "    # Load the corresponding NN test data for the current sample size\n",
        "    nn_test_data = pd.read_csv(f'test_data_nn_sparse_{size}.csv')\n",
        "\n",
        "    # Extract NN predicted probabilities and BN ground truth probabilities\n",
        "    nn_probs = nn_test_data[['Prob_decrease', 'Prob_stable', 'Prob_increase']].values\n",
        "    bn_probs = bn_test_data['SP_Probabilities (decrease, stable, increase)'].apply(\n",
        "        lambda x: np.array(list(map(float, x.strip('[]').split(','))))\n",
        "    ).values\n",
        "\n",
        "    # Calculate K-L divergence between NN predicted probabilities and BN ground truth probabilities\n",
        "    kl_divergences = []\n",
        "    output_data = []  # For tabulating output\n",
        "\n",
        "    for i in range(len(nn_probs)):\n",
        "        nn_prob = nn_probs[i]\n",
        "        bn_prob = bn_probs[i]\n",
        "\n",
        "        # Ensure both are valid probability distributions\n",
        "        epsilon = 1e-10\n",
        "        nn_prob = np.clip(nn_prob, epsilon, 1)\n",
        "        bn_prob = np.clip(bn_prob, epsilon, 1)\n",
        "\n",
        "        # Normalize to ensure they sum to 1\n",
        "        nn_prob /= nn_prob.sum()\n",
        "        bn_prob /= bn_prob.sum()\n",
        "\n",
        "        # Compute K-L divergence\n",
        "        kl_div = entropy(bn_prob, nn_prob)\n",
        "        kl_divergences.append(kl_div)\n",
        "\n",
        "        # Add data to output for tabulation\n",
        "        output_data.append({\n",
        "            'Sample_Index': i,\n",
        "            'IR': bn_test_data.iloc[i]['IR_State'] if 'IR_State' in bn_test_data.columns else None,\n",
        "            'EI': bn_test_data.iloc[i]['EI_State'] if 'EI_State' in bn_test_data.columns else None,\n",
        "            'Ground_Truth_Probs': ', '.join([f'{prob:.4f}' for prob in bn_prob]),\n",
        "            'NN_Probs': ', '.join([f'{prob:.4f}' for prob in nn_prob]),\n",
        "            'KL_Divergence': f'{kl_div:.4f}'\n",
        "        })\n",
        "\n",
        "    # Create a DataFrame for the output data and tabulate the first few rows\n",
        "    output_df = pd.DataFrame(output_data)\n",
        "    print(f\"\\nK-L Divergence Results for {size} samples (First 5 rows):\\n\")\n",
        "    print(tabulate(output_df.head(5), headers='keys', tablefmt='grid'))\n",
        "\n",
        "    # Calculate and display the average K-L divergence for this sample size\n",
        "    average_kl_divergence = np.mean(kl_divergences)\n",
        "    std_kl_divergence = np.std(kl_divergences)\n",
        "    print(f\"\\nAverage K-L Divergence for {size} samples: {average_kl_divergence:.4f}, Std Dev: {std_kl_divergence:.4f}\")\n",
        "\n",
        "    # Append the results to the list\n",
        "    kl_divergence_results.append({\n",
        "        'Sample_Size': size,\n",
        "        'Average_KL_Divergence': average_kl_divergence,\n",
        "        'Std_Dev': std_kl_divergence\n",
        "    })\n",
        "\n",
        "# Save the K-L divergence results to a CSV file\n",
        "kl_divergence_df = pd.DataFrame(kl_divergence_results)\n",
        "kl_divergence_df.to_csv('kl_div_NN_1_10_sparse.csv', index=False)\n",
        "\n",
        "print(\"\\nAll sample sizes have been processed and K-L divergences calculated. Results saved to 'kl_div_NN_3_30_sparse.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GsUJLbLhbc3",
        "outputId": "6ea33b9f-74ed-4c52-9c6e-1d12c485971e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing sample size: 1000\n",
            "\n",
            "K-L Divergence Results for 1000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI   | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+======+========================+========================+=================+\n",
            "|  0 |              0 | high   | good | 0.2038, 0.0124, 0.7838 | 0.2273, 0.0590, 0.7138 |          0.0318 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | medium | good | 0.2038, 0.0124, 0.7838 | 0.2273, 0.0590, 0.7138 |          0.0318 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | high   | poor | 0.2999, 0.4257, 0.2745 | 0.3151, 0.3439, 0.3410 |          0.0163 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | medium | good | 0.2038, 0.0124, 0.7838 | 0.2273, 0.0590, 0.7138 |          0.0318 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | high   | good | 0.2038, 0.0124, 0.7838 | 0.2273, 0.0590, 0.7138 |          0.0318 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 1000 samples: 0.0241, Std Dev: 0.0076\n",
            "\n",
            "Processing sample size: 2000\n",
            "\n",
            "K-L Divergence Results for 2000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+=========+========================+========================+=================+\n",
            "|  0 |              0 | high   | average | 0.1044, 0.5428, 0.3528 | 0.2148, 0.4201, 0.3651 |          0.0516 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | low    | good    | 0.4490, 0.0785, 0.4725 | 0.3737, 0.2543, 0.3720 |          0.1032 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | high   | good    | 0.3954, 0.2537, 0.3509 | 0.3737, 0.2543, 0.3720 |          0.0012 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | medium | good    | 0.4781, 0.0518, 0.4701 | 0.3737, 0.2543, 0.3720 |          0.1454 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | high   | average | 0.1044, 0.5428, 0.3528 | 0.2148, 0.4201, 0.3651 |          0.0516 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 2000 samples: 0.0458, Std Dev: 0.0564\n",
            "\n",
            "Processing sample size: 3000\n",
            "\n",
            "K-L Divergence Results for 3000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR   | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+======+=========+========================+========================+=================+\n",
            "|  0 |              0 | low  | good    | 0.6984, 0.0007, 0.3009 | 0.5535, 0.1414, 0.3051 |          0.1545 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | low  | good    | 0.6984, 0.0007, 0.3009 | 0.5535, 0.1414, 0.3051 |          0.1545 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | low  | good    | 0.6984, 0.0007, 0.3009 | 0.5535, 0.1414, 0.3051 |          0.1545 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | high | good    | 0.4256, 0.1663, 0.4081 | 0.5535, 0.1414, 0.3051 |          0.0339 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | low  | average | 0.4700, 0.3700, 0.1600 | 0.5136, 0.1760, 0.3104 |          0.1272 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 3000 samples: 0.1045, Std Dev: 0.0625\n",
            "\n",
            "Processing sample size: 4000\n",
            "\n",
            "K-L Divergence Results for 4000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+=========+========================+========================+=================+\n",
            "|  0 |              0 | medium | good    | 0.2538, 0.0448, 0.7014 | 0.2695, 0.0649, 0.6656 |          0.0049 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | high   | good    | 0.2538, 0.0448, 0.7014 | 0.2695, 0.0649, 0.6656 |          0.0049 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | high   | good    | 0.2538, 0.0448, 0.7014 | 0.2695, 0.0649, 0.6656 |          0.0049 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | low    | average | 0.4009, 0.1707, 0.4284 | 0.3121, 0.1109, 0.5770 |          0.0464 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | low    | good    | 0.2538, 0.0448, 0.7014 | 0.2695, 0.0649, 0.6656 |          0.0049 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 4000 samples: 0.0100, Std Dev: 0.0151\n",
            "\n",
            "Processing sample size: 5000\n",
            "\n",
            "K-L Divergence Results for 5000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+=========+========================+========================+=================+\n",
            "|  0 |              0 | low    | average | 0.4429, 0.0031, 0.5540 | 0.4047, 0.2805, 0.3149 |          0.339  |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | low    | poor    | 0.1181, 0.3203, 0.5616 | 0.3798, 0.2527, 0.3675 |          0.1761 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | medium | good    | 0.5215, 0.3015, 0.1770 | 0.4262, 0.3077, 0.2661 |          0.0269 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | medium | good    | 0.5215, 0.3015, 0.1770 | 0.4262, 0.3077, 0.2661 |          0.0269 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | medium | average | 0.2795, 0.4996, 0.2209 | 0.4047, 0.2805, 0.3149 |          0.1067 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 5000 samples: 0.1622, Std Dev: 0.1261\n",
            "\n",
            "Processing sample size: 6000\n",
            "\n",
            "K-L Divergence Results for 6000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR   | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+======+=========+========================+========================+=================+\n",
            "|  0 |              0 | low  | good    | 0.2484, 0.2901, 0.4615 | 0.2741, 0.3343, 0.3917 |          0.0102 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | low  | average | 0.3297, 0.4740, 0.1963 | 0.3112, 0.4324, 0.2564 |          0.0102 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | low  | average | 0.3297, 0.4740, 0.1963 | 0.3112, 0.4324, 0.2564 |          0.0102 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | low  | good    | 0.2484, 0.2901, 0.4615 | 0.2741, 0.3343, 0.3917 |          0.0102 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | low  | average | 0.3297, 0.4740, 0.1963 | 0.3112, 0.4324, 0.2564 |          0.0102 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 6000 samples: 0.0137, Std Dev: 0.0114\n",
            "\n",
            "Processing sample size: 7000\n",
            "\n",
            "K-L Divergence Results for 7000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR   | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+======+=========+========================+========================+=================+\n",
            "|  0 |              0 | high | good    | 0.5111, 0.1512, 0.3377 | 0.4365, 0.2456, 0.3178 |          0.0277 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | high | average | 0.2737, 0.4721, 0.2542 | 0.3888, 0.3206, 0.2906 |          0.0526 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | high | poor    | 0.8671, 0.0587, 0.0742 | 0.5703, 0.1977, 0.2319 |          0.2074 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | high | good    | 0.5111, 0.1512, 0.3377 | 0.4365, 0.2456, 0.3178 |          0.0277 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | high | average | 0.2737, 0.4721, 0.2542 | 0.3888, 0.3206, 0.2906 |          0.0526 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 7000 samples: 0.1169, Std Dev: 0.1345\n",
            "\n",
            "Processing sample size: 8000\n",
            "\n",
            "K-L Divergence Results for 8000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR   | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+======+=========+========================+========================+=================+\n",
            "|  0 |              0 | low  | good    | 0.3866, 0.5984, 0.0150 | 0.3297, 0.5437, 0.1265 |          0.0868 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | low  | average | 0.1607, 0.2083, 0.6310 | 0.1702, 0.2704, 0.5595 |          0.0124 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | low  | good    | 0.3866, 0.5984, 0.0150 | 0.3297, 0.5437, 0.1265 |          0.0868 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | low  | average | 0.1607, 0.2083, 0.6310 | 0.1702, 0.2704, 0.5595 |          0.0124 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | low  | poor    | 0.0885, 0.2735, 0.6380 | 0.1700, 0.2702, 0.5598 |          0.029  |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 8000 samples: 0.0394, Std Dev: 0.0320\n",
            "\n",
            "Processing sample size: 9000\n",
            "\n",
            "K-L Divergence Results for 9000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+=========+========================+========================+=================+\n",
            "|  0 |              0 | low    | poor    | 0.3793, 0.1511, 0.4696 | 0.3066, 0.3751, 0.3183 |          0.126  |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | high   | good    | 0.0771, 0.0642, 0.8587 | 0.2404, 0.0948, 0.6648 |          0.1071 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | medium | average | 0.1913, 0.4656, 0.3431 | 0.2951, 0.2052, 0.4997 |          0.1695 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | medium | poor    | 0.1323, 0.5148, 0.3529 | 0.3066, 0.3751, 0.3183 |          0.0882 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | low    | poor    | 0.3793, 0.1511, 0.4696 | 0.3066, 0.3751, 0.3183 |          0.126  |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 9000 samples: 0.0834, Std Dev: 0.0336\n",
            "\n",
            "Processing sample size: 10000\n",
            "\n",
            "K-L Divergence Results for 10000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+=========+========================+========================+=================+\n",
            "|  0 |              0 | high   | poor    | 0.3623, 0.2346, 0.4030 | 0.4035, 0.2472, 0.3493 |          0.0064 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | high   | poor    | 0.3623, 0.2346, 0.4030 | 0.4035, 0.2472, 0.3493 |          0.0064 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | high   | average | 0.7016, 0.2850, 0.0134 | 0.3994, 0.2376, 0.3631 |          0.403  |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | medium | poor    | 0.4085, 0.1697, 0.4218 | 0.4035, 0.2472, 0.3493 |          0.0207 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | low    | good    | 0.5146, 0.2271, 0.2583 | 0.3795, 0.2249, 0.3956 |          0.0488 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 10000 samples: 0.0844, Std Dev: 0.1230\n",
            "\n",
            "All sample sizes have been processed and K-L divergences calculated. Results saved to 'kl_div_NN_3_30_sparse.csv'.\n"
          ]
        }
      ]
    }
  ]
}