{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN80v/gCahjaBI0Oh5vG28u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nonyeezeh/Research-Project-Code/blob/main/NN_Dense_2_10_Relu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "e8f8BQJPd6AH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bpZAeavwc6HF",
        "outputId": "af134603-36be-40ea-848b-462ad160c1d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pgmpy\n",
            "  Downloading pgmpy-0.1.26-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.1.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.1.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.4.1+cu121)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.14.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy) (4.66.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.4.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.3.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.1.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.7.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai->pgmpy) (1.24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost->pgmpy) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->pgmpy) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->pgmpy) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (4.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pgmpy) (1.16.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (4.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai->pgmpy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai->pgmpy) (2.23.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai->pgmpy) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai->pgmpy) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->pgmpy) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2024.8.30)\n",
            "Downloading pgmpy-0.1.26-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pgmpy\n",
            "Successfully installed pgmpy-0.1.26\n"
          ]
        }
      ],
      "source": [
        "pip install pgmpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.sampling import BayesianModelSampling\n",
        "from tabulate import tabulate\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models, layers, callbacks, regularizers\n",
        "\n",
        "from scipy.stats import entropy"
      ],
      "metadata": {
        "id": "vgVUqkkud43V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Network Data Generation 1000, 2000, ..., 10000 Samples (dense)"
      ],
      "metadata": {
        "id": "h7OucFr1eEwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate CPDs\n",
        "def generate_cpds():\n",
        "    # Generate random probabilities for IR\n",
        "    ir_probs = np.random.rand(3)\n",
        "    ir_probs /= ir_probs.sum()  # Normalize to make it a valid probability distribution\n",
        "\n",
        "    # Generate random probabilities for EI given IR\n",
        "    ei_given_ir_probs = np.random.rand(3, 3)\n",
        "    ei_given_ir_probs /= ei_given_ir_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    # Generate random probabilities for SP given IR and EI\n",
        "    sp_probs = np.random.rand(3, 3, 3)\n",
        "    sp_probs /= sp_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    return ir_probs, ei_given_ir_probs, sp_probs\n",
        "\n",
        "# Function to generate and save samples\n",
        "def generate_and_save_samples(ir_probs, ei_probs, sp_probs, sample_size, filename):\n",
        "    output_data = []\n",
        "\n",
        "    # Generate `sample_size` random samples\n",
        "    for _ in range(sample_size):\n",
        "        # Sample `IR` state based on `IR` probabilities\n",
        "        ir_state_idx = np.random.choice(3, p=ir_probs)\n",
        "        ir_state = ['low', 'medium', 'high'][ir_state_idx]\n",
        "        ir_prob = ir_probs[ir_state_idx]\n",
        "\n",
        "        # Sample `EI` state based on `EI` probabilities given `IR`\n",
        "        ei_probs_given_ir = ei_probs[:, ir_state_idx]\n",
        "        ei_state_idx = np.random.choice(3, p=ei_probs_given_ir)\n",
        "        ei_state = ['poor', 'average', 'good'][ei_state_idx]\n",
        "        ei_prob = ei_probs_given_ir[ei_state_idx]\n",
        "\n",
        "        # Sample `SP` state based on `SP` probabilities given `IR` and `EI`\n",
        "        sp_probs_given_ir_ei = sp_probs[:, ir_state_idx, ei_state_idx]\n",
        "        sp_state_idx = np.random.choice(3, p=sp_probs_given_ir_ei)\n",
        "        sp_state = ['decrease', 'stable', 'increase'][sp_state_idx]\n",
        "        sp_prob = sp_probs_given_ir_ei[sp_state_idx]\n",
        "\n",
        "        # Append sample data to output list\n",
        "        output_data.append({\n",
        "            'IR_State': ir_state,\n",
        "            'IR_Prob': f'{ir_prob:.4f}',\n",
        "            'EI_State': ei_state,\n",
        "            'EI_Prob': f'{ei_prob:.4f}',\n",
        "            'SP_Probabilities (decrease, stable, increase)': ', '.join([f'{prob:.4f}' for prob in sp_probs_given_ir_ei]),\n",
        "            'Chosen_SP_State': sp_state,\n",
        "            'Chosen_SP_Probability': f'{sp_prob:.4f}'\n",
        "        })\n",
        "\n",
        "    # Create a DataFrame from the output data\n",
        "    output_df = pd.DataFrame(output_data)\n",
        "\n",
        "    # Save the output DataFrame to a CSV file\n",
        "    output_df.to_csv(filename, index=False)\n",
        "\n",
        "    # Print the first few rows for visual confirmation\n",
        "    print(f\"\\nSample size: {sample_size} - First few rows of generated samples:\\n\")\n",
        "    print(tabulate(output_df.head(), headers='keys', tablefmt='grid'))\n",
        "\n",
        "# Generate and save samples for sample sizes from 1000 to 10000 every 1000\n",
        "sample_sizes = range(1000, 11000, 1000)\n",
        "\n",
        "for size in sample_sizes:\n",
        "    # Generate the CPDs\n",
        "    ir_probs, ei_given_ir_probs, sp_probs = generate_cpds()\n",
        "\n",
        "    # Generate and save individual samples for the given sample size\n",
        "    generate_and_save_samples(ir_probs, ei_given_ir_probs, sp_probs, size, f'combined_probabilities_{size}.csv')\n",
        "\n",
        "# Notify the user that the process is done\n",
        "print(\"\\nGeneration and saving of individual samples complete for all sample sizes!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gi3corAeKvd",
        "outputId": "587d944c-7d94-4a97-f180-817829c3415f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 1000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+\n",
            "|  0 | medium     |    0.479  | average    |    0.5793 | 0.4092, 0.4598, 0.1310                          | decrease          |                  0.4092 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  1 | high       |    0.3953 | poor       |    0.5782 | 0.2334, 0.3833, 0.3833                          | decrease          |                  0.2334 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  2 | medium     |    0.479  | average    |    0.5793 | 0.4092, 0.4598, 0.1310                          | stable            |                  0.4598 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  3 | medium     |    0.479  | good       |    0.2863 | 0.2439, 0.4031, 0.3530                          | stable            |                  0.4031 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  4 | high       |    0.3953 | poor       |    0.5782 | 0.2334, 0.3833, 0.3833                          | stable            |                  0.3833 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "\n",
            "Sample size: 2000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+\n",
            "|  0 | high       |    0.5651 | poor       |    0.7995 | 0.0693, 0.5849, 0.3458                          | increase          |                  0.3458 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  1 | low        |    0.3962 | average    |    0.2403 | 0.1992, 0.1185, 0.6822                          | increase          |                  0.6822 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  2 | low        |    0.3962 | average    |    0.2403 | 0.1992, 0.1185, 0.6822                          | decrease          |                  0.1992 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  3 | high       |    0.5651 | average    |    0.0469 | 0.4248, 0.4809, 0.0943                          | stable            |                  0.4809 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  4 | high       |    0.5651 | poor       |    0.7995 | 0.0693, 0.5849, 0.3458                          | increase          |                  0.3458 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "\n",
            "Sample size: 3000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+\n",
            "|  0 | high       |    0.2831 | poor       |    0.3668 | 0.3272, 0.3656, 0.3072                          | decrease          |                  0.3272 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  1 | low        |    0.2558 | good       |    0.223  | 0.1425, 0.7904, 0.0671                          | stable            |                  0.7904 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  2 | medium     |    0.4611 | good       |    0.5506 | 0.5246, 0.0320, 0.4434                          | increase          |                  0.4434 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  3 | low        |    0.2558 | good       |    0.223  | 0.1425, 0.7904, 0.0671                          | stable            |                  0.7904 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  4 | low        |    0.2558 | poor       |    0.774  | 0.6639, 0.1106, 0.2256                          | decrease          |                  0.6639 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "\n",
            "Sample size: 4000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+\n",
            "|  0 | high       |    0.4204 | average    |    0.6513 | 0.4311, 0.4856, 0.0833                          | stable            |                  0.4856 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  1 | low        |    0.4088 | good       |    0.43   | 0.7478, 0.1028, 0.1494                          | stable            |                  0.1028 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  2 | high       |    0.4204 | average    |    0.6513 | 0.4311, 0.4856, 0.0833                          | increase          |                  0.0833 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  3 | high       |    0.4204 | average    |    0.6513 | 0.4311, 0.4856, 0.0833                          | decrease          |                  0.4311 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  4 | high       |    0.4204 | average    |    0.6513 | 0.4311, 0.4856, 0.0833                          | increase          |                  0.0833 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "\n",
            "Sample size: 5000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+\n",
            "|  0 | low        |    0.5447 | good       |    0.7458 | 0.0292, 0.3784, 0.5923                          | stable            |                  0.3784 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  1 | low        |    0.5447 | good       |    0.7458 | 0.0292, 0.3784, 0.5923                          | stable            |                  0.3784 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  2 | high       |    0.4112 | poor       |    0.4003 | 0.2478, 0.2191, 0.5331                          | increase          |                  0.5331 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  3 | low        |    0.5447 | poor       |    0.1353 | 0.0599, 0.2273, 0.7128                          | stable            |                  0.2273 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  4 | low        |    0.5447 | good       |    0.7458 | 0.0292, 0.3784, 0.5923                          | increase          |                  0.5923 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "\n",
            "Sample size: 6000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+\n",
            "|  0 | high       |    0.403  | poor       |    0.2455 | 0.3110, 0.3537, 0.3354                          | increase          |                  0.3354 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  1 | low        |    0.2266 | poor       |    0.4313 | 0.1187, 0.3829, 0.4984                          | increase          |                  0.4984 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  2 | medium     |    0.3705 | good       |    0.3707 | 0.1072, 0.3538, 0.5390                          | increase          |                  0.539  |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  3 | medium     |    0.3705 | average    |    0.4621 | 0.2483, 0.3856, 0.3661                          | stable            |                  0.3856 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  4 | high       |    0.403  | good       |    0.357  | 0.3554, 0.4385, 0.2061                          | stable            |                  0.4385 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "\n",
            "Sample size: 7000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+\n",
            "|  0 | high       |    0.4644 | poor       |    0.3682 | 0.3177, 0.3963, 0.2860                          | decrease          |                  0.3177 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  1 | medium     |    0.2178 | good       |    0.1732 | 0.7111, 0.0300, 0.2589                          | increase          |                  0.2589 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  2 | low        |    0.3178 | poor       |    0.3371 | 0.0534, 0.4967, 0.4500                          | stable            |                  0.4967 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  3 | low        |    0.3178 | good       |    0.3226 | 0.4628, 0.3692, 0.1680                          | decrease          |                  0.4628 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  4 | high       |    0.4644 | average    |    0.4021 | 0.4450, 0.1728, 0.3822                          | increase          |                  0.3822 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "\n",
            "Sample size: 8000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+\n",
            "|  0 | low        |    0.3339 | average    |    0.4477 | 0.1103, 0.3303, 0.5594                          | increase          |                  0.5594 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  1 | medium     |    0.4626 | average    |    0.5969 | 0.3718, 0.2753, 0.3529                          | decrease          |                  0.3718 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  2 | low        |    0.3339 | poor       |    0.3927 | 0.1774, 0.3746, 0.4480                          | decrease          |                  0.1774 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  3 | low        |    0.3339 | poor       |    0.3927 | 0.1774, 0.3746, 0.4480                          | stable            |                  0.3746 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  4 | medium     |    0.4626 | average    |    0.5969 | 0.3718, 0.2753, 0.3529                          | decrease          |                  0.3718 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "\n",
            "Sample size: 9000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+\n",
            "|  0 | medium     |    0.5255 | poor       |    0.6386 | 0.3772, 0.0033, 0.6196                          | decrease          |                  0.3772 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  1 | low        |    0.1687 | poor       |    0.6982 | 0.3337, 0.4992, 0.1672                          | increase          |                  0.1672 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  2 | medium     |    0.5255 | poor       |    0.6386 | 0.3772, 0.0033, 0.6196                          | decrease          |                  0.3772 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  3 | medium     |    0.5255 | poor       |    0.6386 | 0.3772, 0.0033, 0.6196                          | decrease          |                  0.3772 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  4 | medium     |    0.5255 | average    |    0.314  | 0.1783, 0.4163, 0.4054                          | increase          |                  0.4054 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "\n",
            "Sample size: 10000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|    | IR_State   |   IR_Prob | EI_State   |   EI_Prob | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |   Chosen_SP_Probability |\n",
            "+====+============+===========+============+===========+=================================================+===================+=========================+\n",
            "|  0 | medium     |    0.6024 | good       |    0.3151 | 0.0599, 0.6082, 0.3319                          | increase          |                  0.3319 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  1 | medium     |    0.6024 | poor       |    0.5516 | 0.5573, 0.4217, 0.0210                          | decrease          |                  0.5573 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  2 | low        |    0.2846 | good       |    0.1433 | 0.5546, 0.4060, 0.0393                          | decrease          |                  0.5546 |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  3 | low        |    0.2846 | poor       |    0.85   | 0.3923, 0.0387, 0.5690                          | increase          |                  0.569  |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "|  4 | low        |    0.2846 | poor       |    0.85   | 0.3923, 0.0387, 0.5690                          | increase          |                  0.569  |\n",
            "+----+------------+-----------+------------+-----------+-------------------------------------------------+-------------------+-------------------------+\n",
            "\n",
            "Generation and saving of individual samples complete for all sample sizes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypothesis Model: 1000, 2000, ..., 10000 Samples (dense) 2 hidden Layers, 10 Neurons Relu"
      ],
      "metadata": {
        "id": "3Sr5drrgehgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sizes to loop through\n",
        "sample_sizes = range(1000, 11000, 1000)\n",
        "\n",
        "# Define the Neural Network architecture with L2 regularization\n",
        "def create_nn_model(hidden_layers=2, nodes_per_layer=10, l2_lambda=0.01):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Input layer (2 input features: IR_encoded and EI_encoded)\n",
        "    model.add(layers.InputLayer(input_shape=(2,)))\n",
        "\n",
        "    # Hidden layers with L2 regularization and Dropout\n",
        "    for layer_num in range(hidden_layers):\n",
        "        model.add(layers.Dense(\n",
        "            nodes_per_layer,\n",
        "            activation='relu',\n",
        "            kernel_regularizer=regularizers.l2(l2_lambda),  # L2 regularization\n",
        "            name=f\"hidden_layer_{layer_num + 1}\"\n",
        "        ))\n",
        "        model.add(layers.Dropout(0.2))  # Dropout layer to reduce overfitting\n",
        "\n",
        "    # Output layer (3 classes: decrease, stable, increase) with L2 regularization\n",
        "    model.add(layers.Dense(\n",
        "        3,\n",
        "        activation='softmax',\n",
        "        kernel_regularizer=regularizers.l2(l2_lambda),  # L2 regularization\n",
        "        name=\"output_layer\"\n",
        "    ))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Prepare a dictionary to store the extracted data for each sample size\n",
        "extracted_data = {}\n",
        "\n",
        "# Extract the required columns from all sample sizes first\n",
        "for size in sample_sizes:\n",
        "    # Load data for the current sample size (adjust the file paths if necessary)\n",
        "    outcomes_file = f'combined_probabilities_{size}.csv'\n",
        "    df = pd.read_csv(outcomes_file)\n",
        "\n",
        "    # Extract only the required columns\n",
        "    required_columns = ['IR_State', 'EI_State', 'Chosen_SP_State']\n",
        "    df_extracted = df[required_columns]\n",
        "\n",
        "    # Manually encode categorical variables for IR, EI, and SP\n",
        "    ir_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "    ei_map = {'poor': 0, 'average': 1, 'good': 2}\n",
        "    sp_map = {'decrease': 0, 'stable': 1, 'increase': 2}\n",
        "\n",
        "    df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
        "    df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
        "    df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
        "\n",
        "    # Store the extracted and encoded data for later use\n",
        "    extracted_data[size] = df_extracted\n",
        "\n",
        "# Loop through each sample size for NN training, validation, and testing\n",
        "for size in sample_sizes:\n",
        "    # Retrieve the extracted data for the current sample size\n",
        "    df = extracted_data[size]\n",
        "\n",
        "    # Features (IR and EI) and labels (SP)\n",
        "    X = df[['IR_encoded', 'EI_encoded']]\n",
        "    y = df['SP_encoded']\n",
        "\n",
        "    # Refresh the data split for each iteration\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False, random_state=42)\n",
        "\n",
        "    # Show split confirmation\n",
        "    print(f\"\\nSample size: {size}\")\n",
        "    print(\"Training Data:\", X_train.shape, y_train.shape)\n",
        "    print(\"Validation Data:\", X_val.shape, y_val.shape)\n",
        "    print(\"Test Data:\", X_test.shape, y_test.shape)\n",
        "\n",
        "    # Create the Neural Network model with L2 regularization\n",
        "    nn_model = create_nn_model(hidden_layers=1, nodes_per_layer=10, l2_lambda=0.01)\n",
        "\n",
        "    # Early stopping callback to prevent overfitting\n",
        "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    history = nn_model.fit(X_train, y_train,\n",
        "                           epochs=50,\n",
        "                           batch_size=32,\n",
        "                           validation_data=(X_val, y_val),\n",
        "                           callbacks=[early_stopping],\n",
        "                           verbose=0)  # Set verbose=0 to avoid too much output\n",
        "\n",
        "    # Print training, validation, and test accuracy\n",
        "    train_loss, train_accuracy = nn_model.evaluate(X_train, y_train, verbose=0)\n",
        "    val_loss, val_accuracy = nn_model.evaluate(X_val, y_val, verbose=0)\n",
        "    test_loss, test_accuracy = nn_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"Training Accuracy for {size} samples: {train_accuracy:.4f}\")\n",
        "    print(f\"Validation Accuracy for {size} samples: {val_accuracy:.4f}\")\n",
        "    print(f\"Test Accuracy for {size} samples: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    predictions = nn_model.predict(X_test)\n",
        "\n",
        "    # Convert the predicted probabilities to class labels\n",
        "    predicted_classes = predictions.argmax(axis=1)\n",
        "\n",
        "    # Create a list to map integers back to the original SP labels\n",
        "    sp_reverse_map = ['decrease', 'stable', 'increase']\n",
        "\n",
        "    # Convert the predicted classes to the original labels\n",
        "    predicted_labels = [sp_reverse_map[label] for label in predicted_classes]\n",
        "\n",
        "    # Create a DataFrame for the predicted probabilities\n",
        "    probs_df = pd.DataFrame(predictions, columns=['Prob_decrease', 'Prob_stable', 'Prob_increase'])\n",
        "\n",
        "    # Output the IR, EI, predicted SP, and the NN probabilities\n",
        "    result_df = pd.DataFrame({\n",
        "        'IR': df['IR_State'].iloc[X_test.index],  # IR column from the original dataframe for the test set\n",
        "        'EI': df['EI_State'].iloc[X_test.index],  # EI column from the original dataframe for the test set\n",
        "        'Predicted_SP': predicted_labels           # Predicted SP labels\n",
        "    })\n",
        "\n",
        "    # Combine the result with the predicted probabilities\n",
        "    combined_df = pd.concat([result_df.reset_index(drop=True), probs_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    # Save the test data with predictions to a CSV file\n",
        "    combined_df.to_csv(f'test_data_nn_{size}.csv', index=False)\n",
        "\n",
        "    # Show the first few rows of the results for this sample size\n",
        "    print(f\"\\nPredicted Results and Probabilities for {size} samples (First 15 rows):\")\n",
        "    print(combined_df.head(15))\n",
        "\n",
        "# After the loop is done, print this message\n",
        "print(\"\\nLooping through all sample sizes complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWa4omx3ekNg",
        "outputId": "eb635d58-ccf7-4f1b-86ea-bc52389e93fd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-9ed79f78e975>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
            "<ipython-input-48-9ed79f78e975>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-48-9ed79f78e975>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-48-9ed79f78e975>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
            "<ipython-input-48-9ed79f78e975>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-48-9ed79f78e975>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-48-9ed79f78e975>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
            "<ipython-input-48-9ed79f78e975>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-48-9ed79f78e975>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-48-9ed79f78e975>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
            "<ipython-input-48-9ed79f78e975>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-48-9ed79f78e975>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-48-9ed79f78e975>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
            "<ipython-input-48-9ed79f78e975>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-48-9ed79f78e975>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-48-9ed79f78e975>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
            "<ipython-input-48-9ed79f78e975>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-48-9ed79f78e975>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-48-9ed79f78e975>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
            "<ipython-input-48-9ed79f78e975>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-48-9ed79f78e975>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-48-9ed79f78e975>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
            "<ipython-input-48-9ed79f78e975>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-48-9ed79f78e975>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-48-9ed79f78e975>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
            "<ipython-input-48-9ed79f78e975>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-48-9ed79f78e975>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "<ipython-input-48-9ed79f78e975>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
            "<ipython-input-48-9ed79f78e975>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
            "<ipython-input-48-9ed79f78e975>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 1000\n",
            "Training Data: (700, 2) (700,)\n",
            "Validation Data: (150, 2) (150,)\n",
            "Test Data: (150, 2) (150,)\n",
            "Training Accuracy for 1000 samples: 0.4629\n",
            "Validation Accuracy for 1000 samples: 0.4200\n",
            "Test Accuracy for 1000 samples: 0.3800\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "\n",
            "Predicted Results and Probabilities for 1000 samples (First 15 rows):\n",
            "        IR       EI Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0   medium     good       stable       0.307243     0.466218       0.226539\n",
            "1   medium  average       stable       0.330758     0.386481       0.282761\n",
            "2     high     poor     increase       0.284718     0.327448       0.387833\n",
            "3     high     poor     increase       0.284718     0.327448       0.387833\n",
            "4   medium  average       stable       0.330758     0.386481       0.282761\n",
            "5   medium  average       stable       0.330758     0.386481       0.282761\n",
            "6   medium  average       stable       0.330758     0.386481       0.282761\n",
            "7   medium     good       stable       0.307243     0.466218       0.226539\n",
            "8   medium  average       stable       0.330758     0.386481       0.282761\n",
            "9   medium     good       stable       0.307243     0.466218       0.226539\n",
            "10    high     poor     increase       0.284718     0.327448       0.387833\n",
            "11    high  average       stable       0.292936     0.416137       0.290927\n",
            "12  medium     good       stable       0.307243     0.466218       0.226539\n",
            "13    high     poor     increase       0.284718     0.327448       0.387833\n",
            "14     low     good       stable       0.310014     0.430237       0.259749\n",
            "\n",
            "Sample size: 2000\n",
            "Training Data: (1400, 2) (1400,)\n",
            "Validation Data: (300, 2) (300,)\n",
            "Test Data: (300, 2) (300,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 2000 samples: 0.5300\n",
            "Validation Accuracy for 2000 samples: 0.5600\n",
            "Test Accuracy for 2000 samples: 0.5133\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 2000 samples (First 15 rows):\n",
            "      IR    EI Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0    low  poor       stable       0.251069     0.400663       0.348267\n",
            "1   high  poor       stable       0.111104     0.545525       0.343370\n",
            "2    low  poor       stable       0.251069     0.400663       0.348267\n",
            "3   high  poor       stable       0.111104     0.545525       0.343370\n",
            "4   high  poor       stable       0.111104     0.545525       0.343370\n",
            "5   high  poor       stable       0.111104     0.545525       0.343370\n",
            "6    low  good     increase       0.264981     0.234718       0.500302\n",
            "7   high  poor       stable       0.111104     0.545525       0.343370\n",
            "8   high  poor       stable       0.111104     0.545525       0.343370\n",
            "9   high  good       stable       0.250726     0.444203       0.305071\n",
            "10   low  poor       stable       0.251069     0.400663       0.348267\n",
            "11  high  poor       stable       0.111104     0.545525       0.343370\n",
            "12  high  poor       stable       0.111104     0.545525       0.343370\n",
            "13  high  good       stable       0.250726     0.444203       0.305071\n",
            "14  high  poor       stable       0.111104     0.545525       0.343370\n",
            "\n",
            "Sample size: 3000\n",
            "Training Data: (2100, 2) (2100,)\n",
            "Validation Data: (450, 2) (450,)\n",
            "Test Data: (450, 2) (450,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 3000 samples: 0.4910\n",
            "Validation Accuracy for 3000 samples: 0.4800\n",
            "Test Accuracy for 3000 samples: 0.4644\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 3000 samples (First 15 rows):\n",
            "        IR       EI Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0     high  average     decrease       0.365128     0.294030       0.340842\n",
            "1     high     good     increase       0.381948     0.193225       0.424827\n",
            "2     high     poor       stable       0.326234     0.418180       0.255585\n",
            "3      low     poor     decrease       0.539579     0.224726       0.235695\n",
            "4   medium     good     decrease       0.480153     0.154048       0.365799\n",
            "5     high  average     decrease       0.365128     0.294030       0.340842\n",
            "6   medium     good     decrease       0.480153     0.154048       0.365799\n",
            "7   medium     poor     decrease       0.430785     0.339597       0.229618\n",
            "8     high     good     increase       0.381948     0.193225       0.424827\n",
            "9      low     good       stable       0.319019     0.469723       0.211258\n",
            "10  medium     good     decrease       0.480153     0.154048       0.365799\n",
            "11    high     good     increase       0.381948     0.193225       0.424827\n",
            "12  medium     good     decrease       0.480153     0.154048       0.365799\n",
            "13     low     poor     decrease       0.539579     0.224726       0.235695\n",
            "14  medium     good     decrease       0.480153     0.154048       0.365799\n",
            "\n",
            "Sample size: 4000\n",
            "Training Data: (2800, 2) (2800,)\n",
            "Validation Data: (600, 2) (600,)\n",
            "Test Data: (600, 2) (600,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 4000 samples: 0.5786\n",
            "Validation Accuracy for 4000 samples: 0.5933\n",
            "Test Accuracy for 4000 samples: 0.5983\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 4000 samples (First 15 rows):\n",
            "        IR       EI Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0      low     poor     increase       0.224131     0.324565       0.451305\n",
            "1     high  average       stable       0.435658     0.440885       0.123457\n",
            "2   medium     good     decrease       0.551422     0.267650       0.180929\n",
            "3     high  average       stable       0.435658     0.440885       0.123457\n",
            "4      low     good     decrease       0.707440     0.115081       0.177480\n",
            "5      low     good     decrease       0.707440     0.115081       0.177480\n",
            "6     high  average       stable       0.435658     0.440885       0.123457\n",
            "7     high     poor     decrease       0.499756     0.385935       0.114309\n",
            "8      low     good     decrease       0.707440     0.115081       0.177480\n",
            "9     high  average       stable       0.435658     0.440885       0.123457\n",
            "10    high     poor     decrease       0.499756     0.385935       0.114309\n",
            "11     low  average     decrease       0.446840     0.218534       0.334626\n",
            "12    high  average       stable       0.435658     0.440885       0.123457\n",
            "13    high     poor     decrease       0.499756     0.385935       0.114309\n",
            "14     low     good     decrease       0.707440     0.115081       0.177480\n",
            "\n",
            "Sample size: 5000\n",
            "Training Data: (3500, 2) (3500,)\n",
            "Validation Data: (750, 2) (750,)\n",
            "Test Data: (750, 2) (750,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 5000 samples: 0.5346\n",
            "Validation Accuracy for 5000 samples: 0.5413\n",
            "Test Accuracy for 5000 samples: 0.5187\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 5000 samples (First 15 rows):\n",
            "      IR       EI Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0   high     good     decrease       0.379080     0.295174       0.325746\n",
            "1    low     poor     increase       0.235892     0.270066       0.494042\n",
            "2   high  average     decrease       0.378572     0.283631       0.337797\n",
            "3    low     good     increase       0.095593     0.337157       0.567250\n",
            "4    low     good     increase       0.095593     0.337157       0.567250\n",
            "5   high  average     decrease       0.378572     0.283631       0.337797\n",
            "6   high     good     decrease       0.379080     0.295174       0.325746\n",
            "7   high  average     decrease       0.378572     0.283631       0.337797\n",
            "8    low     poor     increase       0.235892     0.270066       0.494042\n",
            "9   high     poor     increase       0.353917     0.277773       0.368309\n",
            "10   low     good     increase       0.095593     0.337157       0.567250\n",
            "11   low     poor     increase       0.235892     0.270066       0.494042\n",
            "12  high     poor     increase       0.353917     0.277773       0.368309\n",
            "13  high     poor     increase       0.353917     0.277773       0.368309\n",
            "14   low     good     increase       0.095593     0.337157       0.567250\n",
            "\n",
            "Sample size: 6000\n",
            "Training Data: (4200, 2) (4200,)\n",
            "Validation Data: (900, 2) (900,)\n",
            "Test Data: (900, 2) (900,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 6000 samples: 0.4548\n",
            "Validation Accuracy for 6000 samples: 0.4400\n",
            "Test Accuracy for 6000 samples: 0.4656\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 6000 samples (First 15 rows):\n",
            "        IR       EI Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0     high     good       stable       0.286943     0.425608       0.287448\n",
            "1   medium     good     increase       0.167118     0.413194       0.419688\n",
            "2     high     good       stable       0.286943     0.425608       0.287448\n",
            "3     high     good       stable       0.286943     0.425608       0.287448\n",
            "4     high     good       stable       0.286943     0.425608       0.287448\n",
            "5   medium     good     increase       0.167118     0.413194       0.419688\n",
            "6      low     poor     increase       0.173290     0.407799       0.418911\n",
            "7     high     good       stable       0.286943     0.425608       0.287448\n",
            "8     high     good       stable       0.286943     0.425608       0.287448\n",
            "9   medium  average       stable       0.226089     0.422273       0.351639\n",
            "10  medium  average       stable       0.226089     0.422273       0.351639\n",
            "11  medium  average       stable       0.226089     0.422273       0.351639\n",
            "12  medium     poor       stable       0.289588     0.419669       0.290743\n",
            "13    high  average       stable       0.297781     0.426913       0.275306\n",
            "14     low     good     increase       0.093705     0.376543       0.529752\n",
            "\n",
            "Sample size: 7000\n",
            "Training Data: (4900, 2) (4900,)\n",
            "Validation Data: (1050, 2) (1050,)\n",
            "Test Data: (1050, 2) (1050,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 7000 samples: 0.4245\n",
            "Validation Accuracy for 7000 samples: 0.4048\n",
            "Test Accuracy for 7000 samples: 0.4305\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 7000 samples (First 15 rows):\n",
            "        IR       EI Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0     high  average     decrease       0.375842     0.288554       0.335604\n",
            "1      low     poor       stable       0.276387     0.379816       0.343797\n",
            "2      low  average     decrease       0.396928     0.338216       0.264856\n",
            "3   medium     poor       stable       0.292907     0.360226       0.346867\n",
            "4   medium  average     decrease       0.360444     0.317676       0.321881\n",
            "5     high     good     decrease       0.467292     0.245589       0.287119\n",
            "6     high  average     decrease       0.375842     0.288554       0.335604\n",
            "7      low     good     decrease       0.535556     0.275301       0.189143\n",
            "8     high     good     decrease       0.467292     0.245589       0.287119\n",
            "9      low     poor       stable       0.276387     0.379816       0.343797\n",
            "10     low  average     decrease       0.396928     0.338216       0.264856\n",
            "11     low     good     decrease       0.535556     0.275301       0.189143\n",
            "12     low     good     decrease       0.535556     0.275301       0.189143\n",
            "13  medium     good     decrease       0.502229     0.262464       0.235307\n",
            "14  medium     good     decrease       0.502229     0.262464       0.235307\n",
            "\n",
            "Sample size: 8000\n",
            "Training Data: (5600, 2) (5600,)\n",
            "Validation Data: (1200, 2) (1200,)\n",
            "Test Data: (1200, 2) (1200,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 8000 samples: 0.4346\n",
            "Validation Accuracy for 8000 samples: 0.4500\n",
            "Test Accuracy for 8000 samples: 0.4208\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 8000 samples (First 15 rows):\n",
            "        IR       EI Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0     high  average     increase       0.190232     0.262170       0.547598\n",
            "1      low     good       stable       0.331084     0.339650       0.329266\n",
            "2     high  average     increase       0.190232     0.262170       0.547598\n",
            "3   medium     poor     increase       0.276553     0.311905       0.411542\n",
            "4   medium     good       stable       0.327773     0.336327       0.335899\n",
            "5      low     good       stable       0.331084     0.339650       0.329266\n",
            "6      low  average     increase       0.262621     0.325476       0.411903\n",
            "7      low  average     increase       0.262621     0.325476       0.411903\n",
            "8     high  average     increase       0.190232     0.262170       0.547598\n",
            "9      low  average     increase       0.262621     0.325476       0.411903\n",
            "10     low  average     increase       0.262621     0.325476       0.411903\n",
            "11     low  average     increase       0.262621     0.325476       0.411903\n",
            "12  medium  average     increase       0.292845     0.307946       0.399209\n",
            "13     low     poor     increase       0.228432     0.333497       0.438071\n",
            "14     low     poor     increase       0.228432     0.333497       0.438071\n",
            "\n",
            "Sample size: 9000\n",
            "Training Data: (6300, 2) (6300,)\n",
            "Validation Data: (1350, 2) (1350,)\n",
            "Test Data: (1350, 2) (1350,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 9000 samples: 0.4659\n",
            "Validation Accuracy for 9000 samples: 0.4756\n",
            "Test Accuracy for 9000 samples: 0.4570\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 9000 samples (First 15 rows):\n",
            "        IR       EI Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0   medium     poor     increase       0.336002     0.205029       0.458969\n",
            "1   medium     poor     increase       0.336002     0.205029       0.458969\n",
            "2     high  average       stable       0.343540     0.410495       0.245965\n",
            "3   medium     poor     increase       0.336002     0.205029       0.458969\n",
            "4   medium     poor     increase       0.336002     0.205029       0.458969\n",
            "5      low     poor     increase       0.348495     0.259198       0.392307\n",
            "6   medium     poor     increase       0.336002     0.205029       0.458969\n",
            "7      low  average       stable       0.312786     0.353380       0.333835\n",
            "8   medium  average     increase       0.314461     0.304326       0.381213\n",
            "9     high     poor       stable       0.346997     0.388479       0.264523\n",
            "10  medium     poor     increase       0.336002     0.205029       0.458969\n",
            "11  medium  average     increase       0.314461     0.304326       0.381213\n",
            "12    high     good       stable       0.342619     0.427848       0.229533\n",
            "13    high  average       stable       0.343540     0.410495       0.245965\n",
            "14     low  average       stable       0.312786     0.353380       0.333835\n",
            "\n",
            "Sample size: 10000\n",
            "Training Data: (7000, 2) (7000,)\n",
            "Validation Data: (1500, 2) (1500,)\n",
            "Test Data: (1500, 2) (1500,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for 10000 samples: 0.4954\n",
            "Validation Accuracy for 10000 samples: 0.4880\n",
            "Test Accuracy for 10000 samples: 0.4933\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "Predicted Results and Probabilities for 10000 samples (First 15 rows):\n",
            "        IR       EI Predicted_SP  Prob_decrease  Prob_stable  Prob_increase\n",
            "0   medium     good       stable       0.205609     0.486831       0.307560\n",
            "1   medium     good       stable       0.205609     0.486831       0.307560\n",
            "2      low     poor     decrease       0.428265     0.168701       0.403034\n",
            "3   medium     good       stable       0.205609     0.486831       0.307560\n",
            "4   medium     poor     decrease       0.523685     0.364611       0.111703\n",
            "5   medium  average       stable       0.305978     0.348860       0.345162\n",
            "6   medium     poor     decrease       0.523685     0.364611       0.111703\n",
            "7   medium     good       stable       0.205609     0.486831       0.307560\n",
            "8      low     poor     decrease       0.428265     0.168701       0.403034\n",
            "9   medium  average       stable       0.305978     0.348860       0.345162\n",
            "10  medium     good       stable       0.205609     0.486831       0.307560\n",
            "11  medium     good       stable       0.205609     0.486831       0.307560\n",
            "12    high     poor       stable       0.407141     0.570657       0.022202\n",
            "13    high     poor       stable       0.407141     0.570657       0.022202\n",
            "14  medium     good       stable       0.205609     0.486831       0.307560\n",
            "\n",
            "Looping through all sample sizes complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-L Divergence NN Dense Data"
      ],
      "metadata": {
        "id": "GIaNVcsQez3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sizes to loop through\n",
        "sample_sizes = range(1000, 11000, 1000)\n",
        "\n",
        "# Prepare a list to store K-L divergence results\n",
        "kl_divergence_results = []\n",
        "\n",
        "# Loop through each sample size\n",
        "for size in sample_sizes:\n",
        "    print(f\"\\nProcessing sample size: {size}\")\n",
        "\n",
        "    # Load the combined BN data for the current sample size\n",
        "    combined_data_bn = pd.read_csv(f'combined_probabilities_{size}.csv')\n",
        "\n",
        "    # Split the data into train, validation, and test sets\n",
        "    X = combined_data_bn[['IR_State', 'EI_State']]\n",
        "    y = combined_data_bn[['Chosen_SP_State', 'SP_Probabilities (decrease, stable, increase)']]\n",
        "\n",
        "    # Refresh the data split for each iteration\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False, random_state=42)\n",
        "\n",
        "    # Get the test indices\n",
        "    test_indices = X_test.index\n",
        "\n",
        "    # Get the corresponding rows from the combined BN data using the test indices\n",
        "    bn_test_data = combined_data_bn.loc[test_indices]\n",
        "\n",
        "    # Load the corresponding NN test data for the current sample size\n",
        "    nn_test_data = pd.read_csv(f'test_data_nn_{size}.csv')\n",
        "\n",
        "    # Extract NN predicted probabilities and BN ground truth probabilities\n",
        "    nn_probs = nn_test_data[['Prob_decrease', 'Prob_stable', 'Prob_increase']].values\n",
        "    bn_probs = bn_test_data['SP_Probabilities (decrease, stable, increase)'].apply(\n",
        "        lambda x: np.array(list(map(float, x.strip('[]').split(','))))\n",
        "    ).values\n",
        "\n",
        "    # Calculate K-L divergence between NN predicted probabilities and BN ground truth probabilities\n",
        "    kl_divergences = []\n",
        "    output_data = []  # For tabulating output\n",
        "\n",
        "    for i in range(len(nn_probs)):\n",
        "        nn_prob = nn_probs[i]\n",
        "        bn_prob = bn_probs[i]\n",
        "\n",
        "        # Ensure both are valid probability distributions\n",
        "        epsilon = 1e-10\n",
        "        nn_prob = np.clip(nn_prob, epsilon, 1)\n",
        "        bn_prob = np.clip(bn_prob, epsilon, 1)\n",
        "\n",
        "        # Normalize to ensure they sum to 1\n",
        "        nn_prob /= nn_prob.sum()\n",
        "        bn_prob /= bn_prob.sum()\n",
        "\n",
        "        # Compute K-L divergence\n",
        "        kl_div = entropy(bn_prob, nn_prob)\n",
        "        kl_divergences.append(kl_div)\n",
        "\n",
        "        # Add data to output for tabulation\n",
        "        output_data.append({\n",
        "            'Sample_Index': i,\n",
        "            'IR': bn_test_data.iloc[i]['IR_State'],\n",
        "            'EI': bn_test_data.iloc[i]['EI_State'],\n",
        "            'Ground_Truth_Probs': ', '.join([f'{prob:.4f}' for prob in bn_prob]),\n",
        "            'NN_Probs': ', '.join([f'{prob:.4f}' for prob in nn_prob]),\n",
        "            'KL_Divergence': f'{kl_div:.4f}'\n",
        "        })\n",
        "\n",
        "    # Create a DataFrame for the output data and tabulate the first few rows\n",
        "    output_df = pd.DataFrame(output_data)\n",
        "    print(f\"\\nK-L Divergence Results for {size} samples (First 5 rows):\\n\")\n",
        "    print(tabulate(output_df.head(5), headers='keys', tablefmt='grid'))\n",
        "\n",
        "    # Calculate and display the average K-L divergence for this sample size\n",
        "    average_kl_divergence = np.mean(kl_divergences)\n",
        "    std_kl_divergence = np.std(kl_divergences)\n",
        "    print(f\"\\nAverage K-L Divergence for {size} samples: {average_kl_divergence:.4f}, Std Dev: {std_kl_divergence:.4f}\")\n",
        "\n",
        "    # Append the results to the list\n",
        "    kl_divergence_results.append({\n",
        "        'Sample_Size': size,\n",
        "        'Average_KL_Divergence': average_kl_divergence,\n",
        "        'Std_Dev': std_kl_divergence\n",
        "    })\n",
        "\n",
        "# Save the K-L divergence results to a CSV file\n",
        "kl_divergence_df = pd.DataFrame(kl_divergence_results)\n",
        "kl_divergence_df.to_csv('kl_div_NN_2_10_dense.csv', index=False)\n",
        "\n",
        "print(\"\\nAll sample sizes have been processed and K-L divergences calculated. Results saved to 'kl_div_NN_2_10_dense.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IymbmPg3jtnj",
        "outputId": "7f7ef1cc-15bc-4c34-8c4d-49e3215f0df9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing sample size: 1000\n",
            "\n",
            "K-L Divergence Results for 1000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+=========+========================+========================+=================+\n",
            "|  0 |              0 | medium | good    | 0.2439, 0.4031, 0.3530 | 0.3072, 0.4662, 0.2265 |          0.0416 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | medium | average | 0.4092, 0.4598, 0.1310 | 0.3308, 0.3865, 0.2828 |          0.0662 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | high   | poor    | 0.2334, 0.3833, 0.3833 | 0.2847, 0.3274, 0.3878 |          0.0095 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | high   | poor    | 0.2334, 0.3833, 0.3833 | 0.2847, 0.3274, 0.3878 |          0.0095 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | medium | average | 0.4092, 0.4598, 0.1310 | 0.3308, 0.3865, 0.2828 |          0.0662 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 1000 samples: 0.0714, Std Dev: 0.1187\n",
            "\n",
            "Processing sample size: 2000\n",
            "\n",
            "K-L Divergence Results for 2000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+------+------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR   | EI   | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+======+======+========================+========================+=================+\n",
            "|  0 |              0 | low  | poor | 0.2808, 0.4439, 0.2753 | 0.2511, 0.4007, 0.3483 |          0.0122 |\n",
            "+----+----------------+------+------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | high | poor | 0.0693, 0.5849, 0.3458 | 0.1111, 0.5455, 0.3434 |          0.0105 |\n",
            "+----+----------------+------+------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | low  | poor | 0.2808, 0.4439, 0.2753 | 0.2511, 0.4007, 0.3483 |          0.0122 |\n",
            "+----+----------------+------+------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | high | poor | 0.0693, 0.5849, 0.3458 | 0.1111, 0.5455, 0.3434 |          0.0105 |\n",
            "+----+----------------+------+------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | high | poor | 0.0693, 0.5849, 0.3458 | 0.1111, 0.5455, 0.3434 |          0.0105 |\n",
            "+----+----------------+------+------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 2000 samples: 0.0501, Std Dev: 0.0711\n",
            "\n",
            "Processing sample size: 3000\n",
            "\n",
            "K-L Divergence Results for 3000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+=========+========================+========================+=================+\n",
            "|  0 |              0 | high   | average | 0.3011, 0.3785, 0.3204 | 0.3651, 0.2940, 0.3408 |          0.0177 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | high   | good    | 0.5533, 0.0580, 0.3887 | 0.3819, 0.1932, 0.4248 |          0.1007 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | high   | poor    | 0.3272, 0.3656, 0.3072 | 0.3262, 0.4182, 0.2556 |          0.0083 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | low    | poor    | 0.6638, 0.1106, 0.2256 | 0.5396, 0.2247, 0.2357 |          0.0493 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | medium | good    | 0.5246, 0.0320, 0.4434 | 0.4802, 0.1540, 0.3658 |          0.0815 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 3000 samples: 0.1002, Std Dev: 0.1421\n",
            "\n",
            "Processing sample size: 4000\n",
            "\n",
            "K-L Divergence Results for 4000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+=========+========================+========================+=================+\n",
            "|  0 |              0 | low    | poor    | 0.0534, 0.3011, 0.6455 | 0.2241, 0.3246, 0.4513 |          0.1318 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | high   | average | 0.4311, 0.4856, 0.0833 | 0.4357, 0.4409, 0.1235 |          0.0096 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | medium | good    | 0.4519, 0.3526, 0.1955 | 0.5514, 0.2676, 0.1809 |          0.0224 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | high   | average | 0.4311, 0.4856, 0.0833 | 0.4357, 0.4409, 0.1235 |          0.0096 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | low    | good    | 0.7478, 0.1028, 0.1494 | 0.7074, 0.1151, 0.1775 |          0.0042 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 4000 samples: 0.0595, Std Dev: 0.0676\n",
            "\n",
            "Processing sample size: 5000\n",
            "\n",
            "K-L Divergence Results for 5000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR   | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+======+=========+========================+========================+=================+\n",
            "|  0 |              0 | high | good    | 0.4915, 0.1493, 0.3592 | 0.3791, 0.2952, 0.3257 |          0.061  |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | low  | poor    | 0.0599, 0.2273, 0.7128 | 0.2359, 0.2701, 0.4940 |          0.14   |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | high | average | 0.5073, 0.4551, 0.0376 | 0.3786, 0.2836, 0.3378 |          0.2811 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | low  | good    | 0.0292, 0.3784, 0.5924 | 0.0956, 0.3372, 0.5672 |          0.0347 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | low  | good    | 0.0292, 0.3784, 0.5924 | 0.0956, 0.3372, 0.5672 |          0.0347 |\n",
            "+----+----------------+------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 5000 samples: 0.1239, Std Dev: 0.1496\n",
            "\n",
            "Processing sample size: 6000\n",
            "\n",
            "K-L Divergence Results for 6000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI   | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+======+========================+========================+=================+\n",
            "|  0 |              0 | high   | good | 0.3554, 0.4385, 0.2061 | 0.2869, 0.4256, 0.2874 |          0.0206 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | medium | good | 0.1072, 0.3538, 0.5390 | 0.1671, 0.4132, 0.4197 |          0.0324 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | high   | good | 0.3554, 0.4385, 0.2061 | 0.2869, 0.4256, 0.2874 |          0.0206 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | high   | good | 0.3554, 0.4385, 0.2061 | 0.2869, 0.4256, 0.2874 |          0.0206 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | high   | good | 0.3554, 0.4385, 0.2061 | 0.2869, 0.4256, 0.2874 |          0.0206 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 6000 samples: 0.0435, Std Dev: 0.0566\n",
            "\n",
            "Processing sample size: 7000\n",
            "\n",
            "K-L Divergence Results for 7000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+=========+========================+========================+=================+\n",
            "|  0 |              0 | high   | average | 0.4450, 0.1728, 0.3822 | 0.3758, 0.2886, 0.3356 |          0.0363 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | low    | poor    | 0.0534, 0.4967, 0.4500 | 0.2764, 0.3798, 0.3438 |          0.1665 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | low    | average | 0.6241, 0.2564, 0.1195 | 0.3969, 0.3382, 0.2649 |          0.1163 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | medium | poor    | 0.2937, 0.3485, 0.3578 | 0.2929, 0.3602, 0.3469 |          0.0004 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | medium | average | 0.0477, 0.4870, 0.4653 | 0.3604, 0.3177, 0.3219 |          0.2831 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 7000 samples: 0.0720, Std Dev: 0.0835\n",
            "\n",
            "Processing sample size: 8000\n",
            "\n",
            "K-L Divergence Results for 8000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+=========+========================+========================+=================+\n",
            "|  0 |              0 | high   | average | 0.1677, 0.1258, 0.7065 | 0.1902, 0.2622, 0.5476 |          0.0665 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | low    | good    | 0.7268, 0.1711, 0.1021 | 0.3311, 0.3397, 0.3293 |          0.3346 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | high   | average | 0.1677, 0.1258, 0.7065 | 0.1902, 0.2622, 0.5476 |          0.0665 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | medium | poor    | 0.3747, 0.3605, 0.2649 | 0.2766, 0.3119, 0.4115 |          0.0492 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | medium | good    | 0.2692, 0.3929, 0.3379 | 0.3278, 0.3363, 0.3359 |          0.0101 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 8000 samples: 0.0641, Std Dev: 0.0879\n",
            "\n",
            "Processing sample size: 9000\n",
            "\n",
            "K-L Divergence Results for 9000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI      | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+=========+========================+========================+=================+\n",
            "|  0 |              0 | medium | poor    | 0.3772, 0.0033, 0.6195 | 0.3360, 0.2050, 0.4590 |          0.2158 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | medium | poor    | 0.3772, 0.0033, 0.6195 | 0.3360, 0.2050, 0.4590 |          0.2158 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | high   | average | 0.4324, 0.3979, 0.1697 | 0.3435, 0.4105, 0.2460 |          0.0241 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | medium | poor    | 0.3772, 0.0033, 0.6195 | 0.3360, 0.2050, 0.4590 |          0.2158 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | medium | poor    | 0.3772, 0.0033, 0.6195 | 0.3360, 0.2050, 0.4590 |          0.2158 |\n",
            "+----+----------------+--------+---------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 9000 samples: 0.1436, Std Dev: 0.0861\n",
            "\n",
            "Processing sample size: 10000\n",
            "\n",
            "K-L Divergence Results for 10000 samples (First 5 rows):\n",
            "\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|    |   Sample_Index | IR     | EI   | Ground_Truth_Probs     | NN_Probs               |   KL_Divergence |\n",
            "+====+================+========+======+========================+========================+=================+\n",
            "|  0 |              0 | medium | good | 0.0599, 0.6082, 0.3319 | 0.2056, 0.4868, 0.3076 |          0.0868 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|  1 |              1 | medium | good | 0.0599, 0.6082, 0.3319 | 0.2056, 0.4868, 0.3076 |          0.0868 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|  2 |              2 | low    | poor | 0.3923, 0.0387, 0.5690 | 0.4283, 0.1687, 0.4030 |          0.1048 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|  3 |              3 | medium | good | 0.0599, 0.6082, 0.3319 | 0.2056, 0.4868, 0.3076 |          0.0868 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "|  4 |              4 | medium | poor | 0.5573, 0.4217, 0.0210 | 0.5237, 0.3646, 0.1117 |          0.0609 |\n",
            "+----+----------------+--------+------+------------------------+------------------------+-----------------+\n",
            "\n",
            "Average K-L Divergence for 10000 samples: 0.0849, Std Dev: 0.0649\n",
            "\n",
            "All sample sizes have been processed and K-L divergences calculated. Results saved to 'kl_div_NN_2_10_dense.csv'.\n"
          ]
        }
      ]
    }
  ]
}