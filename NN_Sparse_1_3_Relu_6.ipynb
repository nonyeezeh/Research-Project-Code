{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdfnVGjnVRvPW+ewZ9RVg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nonyeezeh/Research-Project-Code/blob/main/NN_Sparse_1_3_Relu_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "TxStpeNDKH_C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5a5f91a5-fb14-4157-f44a-176af4ade275",
        "id": "RMbgaTihKH_D"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pgmpy\n",
            "  Downloading pgmpy-0.1.26-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.2.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.5.0+cu121)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.14.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy) (4.66.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.4.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.4.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.1.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.8.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.16.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost->pgmpy) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->pgmpy) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->pgmpy) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (4.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pgmpy) (1.16.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (4.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai->pgmpy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai->pgmpy) (2.23.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->pgmpy) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2024.8.30)\n",
            "Downloading pgmpy-0.1.26-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pgmpy\n",
            "Successfully installed pgmpy-0.1.26\n"
          ]
        }
      ],
      "source": [
        "pip install pgmpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pgmpy.estimators import HillClimbSearch, BicScore, MaximumLikelihoodEstimator\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.estimators import BayesianEstimator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import entropy\n",
        "from tabulate import tabulate\n",
        "\n",
        "from tensorflow.keras import models, layers, regularizers, callbacks\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tJ_92Jl0KH_D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Network Data Generation 500, ..., 20000 Samples (sparse)"
      ],
      "metadata": {
        "id": "JGOSofbBKH_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o45qZNxH5zrS",
        "outputId": "32dc6637-fc34-4695-9e46-1976a9034106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 50 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | UE_State   | GDP_State   | INF_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+============+=============+=============+=================================================+===================+\n",
            "|  0 | low        | average    | weak        | low        | suburban    | high       | high        | medium      | 0.4253, 0.0024, 0.5724                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | medium     | good       | moderate    | high       | rural       | low        | high        | medium      | 0.0379, 0.2161, 0.7460                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | low        | poor       | moderate    | high       | rural       | low        | high        | medium      | 0.3953, 0.3143, 0.2904                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | low        | good       | strong      | high       | rural       | low        | low         | medium      | 0.3839, 0.4621, 0.1540                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | medium     | poor       | strong      | high       | urban       | high       | low         | high        | 0.4958, 0.2858, 0.2184                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 100 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | UE_State   | GDP_State   | INF_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+============+=============+=============+=================================================+===================+\n",
            "|  0 | low        | poor       | moderate    | low        | rural       | high       | high        | medium      | 0.1436, 0.4057, 0.4507                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | medium     | good       | weak        | high       | urban       | low        | low         | medium      | 0.6788, 0.0961, 0.2251                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | good       | strong      | high       | rural       | low        | low         | medium      | 0.2005, 0.3537, 0.4458                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | high       | poor       | strong      | high       | rural       | high       | high        | medium      | 0.4108, 0.2422, 0.3471                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | high       | average    | weak        | medium     | urban       | medium     | medium      | high        | 0.1090, 0.3981, 0.4929                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 500 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | UE_State   | GDP_State   | INF_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+============+=============+=============+=================================================+===================+\n",
            "|  0 | high       | average    | strong      | high       | urban       | low        | medium      | high        | 0.3178, 0.3529, 0.3293                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | medium     | average    | moderate    | low        | urban       | high       | medium      | high        | 0.2715, 0.1535, 0.5749                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | average    | moderate    | medium     | suburban    | low        | high        | medium      | 0.0804, 0.7035, 0.2161                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | medium     | poor       | strong      | low        | urban       | low        | high        | medium      | 0.0178, 0.4524, 0.5298                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | medium     | average    | strong      | medium     | suburban    | high       | high        | low         | 0.3126, 0.0721, 0.6153                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 1000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | UE_State   | GDP_State   | INF_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+============+=============+=============+=================================================+===================+\n",
            "|  0 | medium     | good       | strong      | medium     | rural       | high       | medium      | low         | 0.4166, 0.2876, 0.2958                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | high       | poor       | moderate    | high       | rural       | high       | medium      | medium      | 0.0665, 0.9012, 0.0323                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | average    | strong      | high       | rural       | medium     | high        | low         | 0.2754, 0.5090, 0.2156                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | high       | poor       | weak        | low        | suburban    | high       | medium      | low         | 0.1910, 0.7428, 0.0662                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | medium     | average    | moderate    | low        | suburban    | medium     | low         | low         | 0.2790, 0.5906, 0.1304                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 5000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | UE_State   | GDP_State   | INF_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+============+=============+=============+=================================================+===================+\n",
            "|  0 | medium     | good       | strong      | low        | urban       | low        | high        | low         | 0.3918, 0.3066, 0.3016                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | low        | poor       | strong      | low        | urban       | low        | medium      | low         | 0.2543, 0.3070, 0.4387                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | low        | good       | strong      | low        | suburban    | medium     | low         | high        | 0.1058, 0.8384, 0.0558                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | medium     | poor       | weak        | medium     | rural       | high       | low         | high        | 0.2352, 0.4606, 0.3042                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | low        | poor       | weak        | low        | suburban    | medium     | medium      | high        | 0.6152, 0.1284, 0.2564                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 10000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | UE_State   | GDP_State   | INF_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+============+=============+=============+=================================================+===================+\n",
            "|  0 | low        | poor       | moderate    | low        | suburban    | high       | medium      | medium      | 0.1121, 0.3346, 0.5533                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | medium     | average    | strong      | low        | suburban    | high       | medium      | medium      | 0.4912, 0.2333, 0.2755                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | good       | moderate    | low        | suburban    | high       | low         | high        | 0.2147, 0.3062, 0.4791                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | low        | poor       | strong      | low        | urban       | low        | high        | low         | 0.4002, 0.2981, 0.3017                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | medium     | average    | strong      | low        | suburban    | medium     | low         | medium      | 0.5667, 0.0425, 0.3908                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 15000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | UE_State   | GDP_State   | INF_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+============+=============+=============+=================================================+===================+\n",
            "|  0 | low        | poor       | moderate    | low        | rural       | low        | low         | low         | 0.1982, 0.6600, 0.1417                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | medium     | good       | moderate    | high       | rural       | low        | low         | high        | 0.2422, 0.5178, 0.2399                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | low        | good       | weak        | low        | rural       | high       | low         | high        | 0.0107, 0.5169, 0.4725                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | low        | average    | weak        | low        | rural       | high       | low         | high        | 0.3099, 0.4551, 0.2350                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | high       | good       | moderate    | medium     | rural       | low        | medium      | medium      | 0.3589, 0.4490, 0.1921                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 20000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | UE_State   | GDP_State   | INF_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+============+=============+=============+=================================================+===================+\n",
            "|  0 | low        | average    | moderate    | high       | urban       | low        | high        | medium      | 0.0080, 0.2950, 0.6970                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | medium     | good       | moderate    | low        | urban       | low        | medium      | high        | 0.2076, 0.3183, 0.4741                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | average    | moderate    | medium     | urban       | high       | high        | low         | 0.1876, 0.2508, 0.5616                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | high       | average    | weak        | low        | urban       | low        | low         | medium      | 0.4668, 0.1558, 0.3774                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | low        | poor       | strong      | low        | urban       | high       | low         | high        | 0.4638, 0.0886, 0.4475                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+------------+-------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Generation and saving of individual samples complete for all sample sizes!\n"
          ]
        }
      ],
      "source": [
        "# Function to generate CPDs for the sparse structure with 9 nodes influencing SP\n",
        "def generate_cpds_sparse_9_total_nodes():\n",
        "    # Generate random probabilities for the independent nodes\n",
        "    ir_probs = np.random.rand(3)\n",
        "    ir_probs /= ir_probs.sum()\n",
        "\n",
        "    # Create diverse dependency structures for the nodes\n",
        "    ei_given_ir_probs = np.random.rand(3, 3)\n",
        "    ei_given_ir_probs /= ei_given_ir_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    irt_given_ei_probs = np.random.rand(3, 3)\n",
        "    irt_given_ei_probs /= irt_given_ei_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    ms_given_irt_probs = np.random.rand(3, 3)\n",
        "    ms_given_irt_probs /= ms_given_irt_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    geo_given_ms_probs = np.random.rand(3, 3)\n",
        "    geo_given_ms_probs /= geo_given_ms_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    ue_given_geo_probs = np.random.rand(3, 3)\n",
        "    ue_given_geo_probs /= ue_given_geo_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    gdp_given_ue_probs = np.random.rand(3, 3)\n",
        "    gdp_given_ue_probs /= gdp_given_ue_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    inf_given_gdp_probs = np.random.rand(3, 3)\n",
        "    inf_given_gdp_probs /= inf_given_gdp_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    # SP depends on all 9 nodes without interactions between them\n",
        "    sp_probs = np.random.rand(3, 3, 3, 3, 3, 3, 3, 3, 3)\n",
        "    sp_probs /= sp_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    return (ir_probs, ei_given_ir_probs, irt_given_ei_probs, ms_given_irt_probs,\n",
        "            geo_given_ms_probs, ue_given_geo_probs, gdp_given_ue_probs, inf_given_gdp_probs, sp_probs)\n",
        "\n",
        "# Function to generate and save samples with the sparse structure of 9 nodes total\n",
        "def generate_and_save_samples_sparse_9_total_nodes(ir_probs, ei_probs, irt_probs, ms_probs, geo_probs, ue_probs, gdp_probs, inf_probs, sp_probs, sample_size, filename):\n",
        "    output_data = []\n",
        "\n",
        "    # Generate `sample_size` random samples\n",
        "    for _ in range(sample_size):\n",
        "        # Sample the independent node first\n",
        "        ir_state_idx = np.random.choice(3, p=ir_probs)\n",
        "        ir_state = ['low', 'medium', 'high'][ir_state_idx]\n",
        "\n",
        "        # Sample dependent nodes based on the new mixed dependency structure\n",
        "        ei_probs_given_ir = ei_probs[:, ir_state_idx]\n",
        "        ei_state_idx = np.random.choice(3, p=ei_probs_given_ir)\n",
        "        ei_state = ['poor', 'average', 'good'][ei_state_idx]\n",
        "\n",
        "        irt_probs_given_ei = irt_probs[:, ei_state_idx]\n",
        "        irt_state_idx = np.random.choice(3, p=irt_probs_given_ei)\n",
        "        irt_state = ['weak', 'moderate', 'strong'][irt_state_idx]\n",
        "\n",
        "        ms_probs_given_irt = ms_probs[:, irt_state_idx]\n",
        "        ms_state_idx = np.random.choice(3, p=ms_probs_given_irt)\n",
        "        ms_state = ['low', 'medium', 'high'][ms_state_idx]\n",
        "\n",
        "        geo_probs_given_ms = geo_probs[:, ms_state_idx]\n",
        "        geo_state_idx = np.random.choice(3, p=geo_probs_given_ms)\n",
        "        geo_state = ['urban', 'suburban', 'rural'][geo_state_idx]\n",
        "\n",
        "        ue_probs_given_geo = ue_probs[:, geo_state_idx]\n",
        "        ue_state_idx = np.random.choice(3, p=ue_probs_given_geo)\n",
        "        ue_state = ['low', 'medium', 'high'][ue_state_idx]\n",
        "\n",
        "        gdp_probs_given_ue = gdp_probs[:, ue_state_idx]\n",
        "        gdp_state_idx = np.random.choice(3, p=gdp_probs_given_ue)\n",
        "        gdp_state = ['low', 'medium', 'high'][gdp_state_idx]\n",
        "\n",
        "        inf_probs_given_gdp = inf_probs[:, gdp_state_idx]\n",
        "        inf_state_idx = np.random.choice(3, p=inf_probs_given_gdp)\n",
        "        inf_state = ['low', 'medium', 'high'][inf_state_idx]\n",
        "\n",
        "        # Calculate SP probability based on the state of each node (sparse dependency on each)\n",
        "        sp_probs_given_all = sp_probs[:, ir_state_idx, ei_state_idx, irt_state_idx, ms_state_idx, geo_state_idx, ue_state_idx, gdp_state_idx, inf_state_idx]\n",
        "        sp_state_idx = np.random.choice(3, p=sp_probs_given_all)\n",
        "        sp_state = ['decrease', 'stable', 'increase'][sp_state_idx]\n",
        "\n",
        "        # Append sample data to output list including probabilities for all nodes\n",
        "        output_data.append({\n",
        "            'IR_State': ir_state,\n",
        "            'EI_State': ei_state,\n",
        "            'IRT_State': irt_state,\n",
        "            'MS_State': ms_state,\n",
        "            'GEO_State': geo_state,\n",
        "            'UE_State': ue_state,\n",
        "            'GDP_State': gdp_state,\n",
        "            'INF_State': inf_state,\n",
        "            'SP_Probabilities (decrease, stable, increase)': ', '.join([f'{prob:.4f}' for prob in sp_probs_given_all]),\n",
        "            'Chosen_SP_State': sp_state\n",
        "        })\n",
        "\n",
        "    # Create a DataFrame from the output data\n",
        "    output_df = pd.DataFrame(output_data)\n",
        "\n",
        "    # Save the output DataFrame to a CSV file\n",
        "    output_df.to_csv(filename, index=False)\n",
        "\n",
        "    # Print the first few rows for visual confirmation\n",
        "    print(f\"\\nSample size: {sample_size} - First few rows of generated samples:\\n\")\n",
        "    print(tabulate(output_df.head(), headers='keys', tablefmt='grid'))\n",
        "\n",
        "# Generate and save samples for sample sizes\n",
        "sample_sizes = [50, 100, 500, 1000, 5000, 10000, 15000, 20000]\n",
        "\n",
        "for size in sample_sizes:\n",
        "    (ir_probs, ei_probs, irt_probs, ms_probs, geo_probs, ue_probs, gdp_probs, inf_probs, sp_probs) = generate_cpds_sparse_9_total_nodes()\n",
        "    generate_and_save_samples_sparse_9_total_nodes(ir_probs, ei_probs, irt_probs, ms_probs, geo_probs, ue_probs, gdp_probs, inf_probs, sp_probs, size, f'combined_probabilities_{size}.csv')\n",
        "\n",
        "print(\"\\nGeneration and saving of individual samples complete for all sample sizes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN & KL-Div"
      ],
      "metadata": {
        "id": "kzPGQCbLRikp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sizes to loop through\n",
        "sample_sizes = [50, 100, 500, 1000, 5000, 10000, 15000, 20000]\n",
        "# Define the Neural Network architecture with L2 regularization\n",
        "def create_nn_model(hidden_layers=1, nodes_per_layer=3, l2_lambda=0.01):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=(8,)))  # Updated input shape to include 5 features\n",
        "\n",
        "    # Hidden layers with L2 regularization and Dropout\n",
        "    for layer_num in range(hidden_layers):\n",
        "        model.add(layers.Dense(\n",
        "            nodes_per_layer,\n",
        "            activation='relu',\n",
        "            kernel_regularizer=regularizers.l2(l2_lambda),  # L2 regularization\n",
        "            name=f\"hidden_layer_{layer_num + 1}\"\n",
        "        ))\n",
        "        model.add(layers.Dropout(0.2))  # Dropout layer to reduce overfitting\n",
        "\n",
        "    # Output layer (3 classes: decrease, stable, increase) with L2 regularization\n",
        "    model.add(layers.Dense(\n",
        "        3,\n",
        "        activation='softmax',\n",
        "        kernel_regularizer=regularizers.l2(l2_lambda),\n",
        "        name=\"output_layer\"\n",
        "    ))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Prepare a dictionary to store extracted data for each sample size\n",
        "extracted_data = {}\n",
        "\n",
        "# Extract the required columns from all sample sizes first\n",
        "for size in sample_sizes:\n",
        "    outcomes_file = f'combined_probabilities_{size}.csv'\n",
        "    df = pd.read_csv(outcomes_file)\n",
        "\n",
        "    # Include new nodes in the required columns\n",
        "    required_columns = ['IR_State', 'EI_State', 'IRT_State', 'MS_State', 'GEO_State', 'UE_State', 'GDP_State', 'INF_State','Chosen_SP_State']\n",
        "    df_extracted = df[required_columns]\n",
        "\n",
        "    # Encode categorical variables for IR, EI, IRT, MS, GEO, and SP\n",
        "    ir_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "    ei_map = {'poor': 0, 'average': 1, 'good': 2}\n",
        "    irt_map = {'weak': 0, 'moderate': 1, 'strong': 2}\n",
        "    ms_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "    geo_map = {'urban': 0, 'suburban': 1, 'rural': 2}\n",
        "    ue_probs_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "    gdp_probs_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "    inf_probs_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "    sp_map = {'decrease': 0, 'stable': 1, 'increase': 2}\n",
        "\n",
        "    df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
        "    df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
        "    df_extracted['IRT_encoded'] = df_extracted['IRT_State'].map(irt_map)\n",
        "    df_extracted['MS_encoded'] = df_extracted['MS_State'].map(ms_map)\n",
        "    df_extracted['GEO_encoded'] = df_extracted['GEO_State'].map(geo_map)\n",
        "    df_extracted['UE_encoded'] = df_extracted['UE_State'].map(ue_probs_map)\n",
        "    df_extracted['GDP_encoded'] = df_extracted['GDP_State'].map(gdp_probs_map)\n",
        "    df_extracted['INF_encoded'] = df_extracted['INF_State'].map(inf_probs_map)\n",
        "    df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
        "\n",
        "    extracted_data[size] = df_extracted\n",
        "\n",
        "# Initialize list to store K-L divergence and standard deviation results\n",
        "results = []\n",
        "epsilon = 1e-10  # Small value for smoothing\n",
        "\n",
        "for size in sample_sizes:\n",
        "    df = extracted_data[size]\n",
        "\n",
        "    # Features (IR, EI, IRT, MS, GEO) and labels (SP)\n",
        "    X = df[['IR_encoded', 'EI_encoded', 'IRT_encoded', 'MS_encoded', 'GEO_encoded', 'UE_encoded', 'GDP_encoded', 'INF_encoded']]\n",
        "    y = df['SP_encoded']\n",
        "\n",
        "    # Split into training, validation, and test sets\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Create and train the Neural Network model\n",
        "    nn_model = create_nn_model(hidden_layers=1, nodes_per_layer=3, l2_lambda=0.01)\n",
        "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    nn_model.fit(X_train, y_train, epochs=25, batch_size=16, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "    # Evaluate model accuracy\n",
        "    train_loss, train_accuracy = nn_model.evaluate(X_train, y_train, verbose=0)\n",
        "    val_loss, val_accuracy = nn_model.evaluate(X_val, y_val, verbose=0)\n",
        "    test_loss, test_accuracy = nn_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"\\nSample size: {size}\")\n",
        "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Predict on test data\n",
        "    predictions = nn_model.predict(X_test)\n",
        "    predicted_classes = predictions.argmax(axis=1)\n",
        "\n",
        "    # Calculate ground truth and predicted probabilities\n",
        "    ground_truth_probabilities = y_test.value_counts(normalize=True).sort_index()\n",
        "    predicted_probabilities = pd.Series(predicted_classes).value_counts(normalize=True).sort_index()\n",
        "\n",
        "    # Reindex both distributions and add smoothing\n",
        "    all_categories = sorted(set(ground_truth_probabilities.index).union(set(predicted_probabilities.index)))\n",
        "    ground_truth_probabilities = ground_truth_probabilities.reindex(all_categories, fill_value=epsilon)\n",
        "    predicted_probabilities = predicted_probabilities.reindex(all_categories, fill_value=epsilon)\n",
        "\n",
        "    # Calculate K-L divergence and standard deviation\n",
        "    kl_divergence = entropy(pk=ground_truth_probabilities, qk=predicted_probabilities)\n",
        "    std_dev = np.std(predicted_probabilities - ground_truth_probabilities)\n",
        "\n",
        "    results.append({\n",
        "        'Sample_Size': size,\n",
        "        'K-L_Divergence': kl_divergence,\n",
        "        'Standard_Deviation': std_dev\n",
        "    })\n",
        "\n",
        "    print(f\"K-L Divergence: {kl_divergence:.4f}\")\n",
        "    print(f\"Standard Deviation: {std_dev:.4f}\")\n",
        "\n",
        "    # Map integers back to the original SP labels\n",
        "    sp_reverse_map = ['decrease', 'stable', 'increase']\n",
        "    predicted_labels = [sp_reverse_map[label] for label in predicted_classes]\n",
        "\n",
        "    # Create DataFrame for displaying nodes, predicted SP, and chosen SP\n",
        "    result_df = pd.DataFrame({\n",
        "        'IR_State': df['IR_State'].iloc[X_test.index],\n",
        "        'EI_State': df['EI_State'].iloc[X_test.index],\n",
        "        'IRT_State': df['IRT_State'].iloc[X_test.index],\n",
        "        'MS_State': df['MS_State'].iloc[X_test.index],\n",
        "        'GEO_State': df['GEO_State'].iloc[X_test.index],\n",
        "        'UE_State': df['UE_State'].iloc[X_test.index],\n",
        "        'GDP_State': df['GDP_State'].iloc[X_test.index],\n",
        "        'INF_State': df['INF_State'].iloc[X_test.index],\n",
        "        'Chosen_SP': df['Chosen_SP_State'].iloc[X_test.index],\n",
        "        'Predicted_SP': predicted_labels\n",
        "    })\n",
        "    print(f\"\\nPredicted Results for {size} samples (First 10 rows):\")\n",
        "    print(result_df.head(10))\n",
        "\n",
        "    # Save results for this sample size in a dedicated CSV\n",
        "    result_df.to_csv(f'test_results_{size}.csv', index=False)\n",
        "\n",
        "# Save only K-L and Standard Deviation results to a summary file\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('kl_std_results_summary.csv', index=False)\n",
        "\n",
        "print(\"\\nAll K-L divergence and standard deviation results have been saved in 'kl_std_results_summary.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8caooazSA-9B",
        "outputId": "8dcb29b2-ba64-420b-bc80-62a8849492e7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 50\n",
            "Training Accuracy: 0.3714\n",
            "Validation Accuracy: 0.4286\n",
            "Test Accuracy: 0.5000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "K-L Divergence: 5.2726\n",
            "Standard Deviation: 0.2041\n",
            "\n",
            "Predicted Results for 50 samples (First 10 rows):\n",
            "   IR_State EI_State IRT_State MS_State GEO_State UE_State GDP_State  \\\n",
            "19      low  average  moderate     high     urban     high       low   \n",
            "4    medium     poor    strong     high     urban     high       low   \n",
            "13      low     poor    strong     high     rural     high       low   \n",
            "8    medium  average    strong      low  suburban      low      high   \n",
            "48   medium     poor    strong      low  suburban     high       low   \n",
            "32      low  average      weak     high     urban     high       low   \n",
            "30   medium     poor  moderate     high     rural      low      high   \n",
            "39      low  average    strong      low     urban      low      high   \n",
            "\n",
            "   INF_State Chosen_SP Predicted_SP  \n",
            "19    medium    stable     decrease  \n",
            "4       high    stable     decrease  \n",
            "13    medium  increase       stable  \n",
            "8     medium    stable       stable  \n",
            "48    medium    stable       stable  \n",
            "32       low  decrease     decrease  \n",
            "30    medium    stable       stable  \n",
            "39       low  increase       stable  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 100\n",
            "Training Accuracy: 0.3000\n",
            "Validation Accuracy: 0.4667\n",
            "Test Accuracy: 0.2667\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "K-L Divergence: 7.2015\n",
            "Standard Deviation: 0.3399\n",
            "\n",
            "Predicted Results for 100 samples (First 10 rows):\n",
            "   IR_State EI_State IRT_State MS_State GEO_State UE_State GDP_State  \\\n",
            "96   medium     good    strong     high     rural   medium      high   \n",
            "4      high  average      weak   medium     urban   medium    medium   \n",
            "42     high     poor  moderate      low     urban      low    medium   \n",
            "77   medium  average      weak   medium  suburban   medium      high   \n",
            "10     high  average      weak   medium     rural      low    medium   \n",
            "0       low     poor  moderate      low     rural     high      high   \n",
            "9    medium     poor  moderate      low     rural     high      high   \n",
            "69   medium     good      weak     high  suburban      low       low   \n",
            "73     high  average  moderate     high     rural   medium    medium   \n",
            "83     high  average      weak   medium     urban   medium    medium   \n",
            "\n",
            "   INF_State Chosen_SP Predicted_SP  \n",
            "96       low  decrease       stable  \n",
            "4       high  increase       stable  \n",
            "42      high  increase       stable  \n",
            "77      high    stable       stable  \n",
            "10      high  decrease       stable  \n",
            "0     medium  decrease     increase  \n",
            "9        low  decrease     increase  \n",
            "69    medium  decrease       stable  \n",
            "73      high  increase       stable  \n",
            "83    medium    stable       stable  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 500\n",
            "Training Accuracy: 0.2943\n",
            "Validation Accuracy: 0.3600\n",
            "Test Accuracy: 0.3600\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "K-L Divergence: 0.0545\n",
            "Standard Deviation: 0.1072\n",
            "\n",
            "Predicted Results for 500 samples (First 10 rows):\n",
            "    IR_State EI_State IRT_State MS_State GEO_State UE_State GDP_State  \\\n",
            "290      low     poor    strong   medium     rural      low    medium   \n",
            "316   medium     good      weak      low     rural      low      high   \n",
            "117     high     good    strong      low     urban   medium       low   \n",
            "455     high  average      weak      low     urban     high      high   \n",
            "268   medium     poor  moderate      low     urban   medium      high   \n",
            "336     high     good    strong   medium  suburban     high    medium   \n",
            "79    medium  average      weak      low     urban   medium       low   \n",
            "208   medium     poor  moderate     high     urban      low      high   \n",
            "238      low  average    strong     high  suburban      low       low   \n",
            "477     high     good  moderate      low     urban      low      high   \n",
            "\n",
            "    INF_State Chosen_SP Predicted_SP  \n",
            "290      high  decrease     increase  \n",
            "316    medium  increase     increase  \n",
            "117    medium  increase       stable  \n",
            "455       low  decrease     decrease  \n",
            "268    medium  increase     increase  \n",
            "336       low  increase       stable  \n",
            "79        low  increase       stable  \n",
            "208    medium  increase     increase  \n",
            "238      high  decrease     increase  \n",
            "477       low  decrease     increase  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 1000\n",
            "Training Accuracy: 0.3457\n",
            "Validation Accuracy: 0.3333\n",
            "Test Accuracy: 0.3200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "K-L Divergence: 8.3870\n",
            "Standard Deviation: 0.2788\n",
            "\n",
            "Predicted Results for 1000 samples (First 10 rows):\n",
            "    IR_State EI_State IRT_State MS_State GEO_State UE_State GDP_State  \\\n",
            "557     high     poor  moderate     high     rural   medium    medium   \n",
            "798     high     poor    strong   medium     urban      low      high   \n",
            "977     high     poor      weak   medium     urban      low      high   \n",
            "136     high     poor      weak   medium     urban      low      high   \n",
            "575   medium     good    strong   medium     urban     high      high   \n",
            "544     high     poor      weak   medium     rural      low       low   \n",
            "332   medium     poor  moderate     high     rural      low      high   \n",
            "917   medium  average      weak      low     rural   medium      high   \n",
            "678   medium     good      weak   medium     rural   medium    medium   \n",
            "363   medium  average    strong      low  suburban   medium      high   \n",
            "\n",
            "    INF_State Chosen_SP Predicted_SP  \n",
            "557       low    stable     increase  \n",
            "798       low  increase     increase  \n",
            "977       low  increase       stable  \n",
            "136      high  increase       stable  \n",
            "575       low    stable     increase  \n",
            "544    medium  increase       stable  \n",
            "332       low  increase       stable  \n",
            "917    medium  increase       stable  \n",
            "678       low    stable       stable  \n",
            "363       low  decrease       stable  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 5000\n",
            "Training Accuracy: 0.3431\n",
            "Validation Accuracy: 0.3587\n",
            "Test Accuracy: 0.3587\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "K-L Divergence: 13.6711\n",
            "Standard Deviation: 0.4537\n",
            "\n",
            "Predicted Results for 5000 samples (First 10 rows):\n",
            "     IR_State EI_State IRT_State MS_State GEO_State UE_State GDP_State  \\\n",
            "790    medium  average  moderate      low     urban   medium    medium   \n",
            "2879      low     poor    strong      low     urban     high      high   \n",
            "2372   medium     good      weak     high  suburban      low      high   \n",
            "1351   medium     good      weak      low  suburban      low      high   \n",
            "3382   medium     poor      weak      low  suburban     high    medium   \n",
            "3433     high  average      weak      low     urban   medium      high   \n",
            "1129   medium     good    strong     high     urban     high       low   \n",
            "549       low     poor      weak     high     urban   medium    medium   \n",
            "2835   medium  average  moderate   medium     urban      low    medium   \n",
            "626      high  average      weak   medium     urban      low       low   \n",
            "\n",
            "     INF_State Chosen_SP Predicted_SP  \n",
            "790        low  decrease     increase  \n",
            "2879       low  decrease     increase  \n",
            "2372    medium  decrease     increase  \n",
            "1351    medium    stable     increase  \n",
            "3382      high    stable     increase  \n",
            "3433       low  decrease     increase  \n",
            "1129       low  increase     increase  \n",
            "549       high  increase     increase  \n",
            "2835      high  decrease     increase  \n",
            "626       high  decrease     increase  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 10000\n",
            "Training Accuracy: 0.3366\n",
            "Validation Accuracy: 0.3380\n",
            "Test Accuracy: 0.3487\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "K-L Divergence: 13.8996\n",
            "Standard Deviation: 0.4606\n",
            "\n",
            "Predicted Results for 10000 samples (First 10 rows):\n",
            "     IR_State EI_State IRT_State MS_State GEO_State UE_State GDP_State  \\\n",
            "2697      low     poor    strong      low  suburban     high       low   \n",
            "6871      low     good      weak   medium     urban      low    medium   \n",
            "3487      low     poor    strong      low     urban     high       low   \n",
            "92       high     poor  moderate      low     urban     high    medium   \n",
            "9537      low     good  moderate      low  suburban      low    medium   \n",
            "3205   medium  average  moderate     high  suburban   medium      high   \n",
            "6641      low     poor    strong      low     urban     high      high   \n",
            "8909     high     poor    strong      low     urban     high      high   \n",
            "2884     high     poor  moderate      low     urban   medium      high   \n",
            "7173   medium  average  moderate      low     urban     high       low   \n",
            "\n",
            "     INF_State Chosen_SP Predicted_SP  \n",
            "2697    medium  increase     increase  \n",
            "6871       low  decrease     increase  \n",
            "3487       low  decrease     increase  \n",
            "92         low  increase     increase  \n",
            "9537       low    stable     increase  \n",
            "3205       low  increase     increase  \n",
            "6641       low    stable     increase  \n",
            "8909       low    stable     increase  \n",
            "2884    medium    stable     increase  \n",
            "7173       low    stable     increase  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 15000\n",
            "Training Accuracy: 0.3394\n",
            "Validation Accuracy: 0.3556\n",
            "Test Accuracy: 0.3218\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "K-L Divergence: 14.5184\n",
            "Standard Deviation: 0.4796\n",
            "\n",
            "Predicted Results for 15000 samples (First 10 rows):\n",
            "      IR_State EI_State IRT_State MS_State GEO_State UE_State GDP_State  \\\n",
            "8602    medium     poor  moderate   medium  suburban   medium       low   \n",
            "438     medium     poor  moderate      low     urban   medium       low   \n",
            "8094    medium  average      weak     high  suburban      low       low   \n",
            "14355   medium     good      weak     high  suburban      low    medium   \n",
            "8581       low  average  moderate      low     rural     high       low   \n",
            "12358      low  average    strong   medium     urban   medium      high   \n",
            "511        low  average      weak     high  suburban   medium    medium   \n",
            "6594       low  average  moderate   medium     urban      low    medium   \n",
            "5245    medium     poor    strong   medium     rural      low    medium   \n",
            "5437       low     good      weak      low     rural     high    medium   \n",
            "\n",
            "      INF_State Chosen_SP Predicted_SP  \n",
            "8602        low  increase     increase  \n",
            "438      medium  decrease     increase  \n",
            "8094       high    stable     increase  \n",
            "14355      high  increase     increase  \n",
            "8581       high  increase     increase  \n",
            "12358       low    stable     increase  \n",
            "511      medium  increase     increase  \n",
            "6594       high  decrease     increase  \n",
            "5245       high  increase     increase  \n",
            "5437     medium  increase     increase  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 20000\n",
            "Training Accuracy: 0.3396\n",
            "Validation Accuracy: 0.3503\n",
            "Test Accuracy: 0.3450\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "K-L Divergence: 13.9838\n",
            "Standard Deviation: 0.4632\n",
            "\n",
            "Predicted Results for 20000 samples (First 10 rows):\n",
            "      IR_State EI_State IRT_State MS_State GEO_State UE_State GDP_State  \\\n",
            "5348      high     good      weak      low     urban      low    medium   \n",
            "339       high     good    strong   medium     urban      low      high   \n",
            "13591     high  average  moderate      low     urban      low       low   \n",
            "8153       low     good      weak      low     rural   medium    medium   \n",
            "16345   medium  average  moderate   medium  suburban      low       low   \n",
            "16404     high  average  moderate      low  suburban     high    medium   \n",
            "17185     high  average  moderate      low  suburban     high      high   \n",
            "5709    medium     poor    strong      low  suburban      low      high   \n",
            "13020      low     poor    strong   medium     rural   medium    medium   \n",
            "7763       low     good  moderate      low     urban     high       low   \n",
            "\n",
            "      INF_State Chosen_SP Predicted_SP  \n",
            "5348       high  decrease     increase  \n",
            "339      medium    stable     increase  \n",
            "13591      high  increase     increase  \n",
            "8153       high    stable     increase  \n",
            "16345      high    stable     increase  \n",
            "16404      high  decrease     increase  \n",
            "17185    medium  decrease     increase  \n",
            "5709       high  decrease     increase  \n",
            "13020      high  decrease     increase  \n",
            "7763       high    stable     increase  \n",
            "\n",
            "All K-L divergence and standard deviation results have been saved in 'kl_std_results_summary.csv'.\n"
          ]
        }
      ]
    }
  ]
}