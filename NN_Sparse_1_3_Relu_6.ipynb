{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNki9xwrNhhMzDo2JgEZtk4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nonyeezeh/Research-Project-Code/blob/main/NN_Sparse_1_3_Relu_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "TxStpeNDKH_C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5a5f91a5-fb14-4157-f44a-176af4ade275",
        "id": "RMbgaTihKH_D"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pgmpy\n",
            "  Downloading pgmpy-0.1.26-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.2.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.5.0+cu121)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.14.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy) (4.66.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.4.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.4.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.1.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.8.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.16.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost->pgmpy) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->pgmpy) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->pgmpy) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (4.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pgmpy) (1.16.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (4.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai->pgmpy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai->pgmpy) (2.23.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->pgmpy) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2024.8.30)\n",
            "Downloading pgmpy-0.1.26-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pgmpy\n",
            "Successfully installed pgmpy-0.1.26\n"
          ]
        }
      ],
      "source": [
        "pip install pgmpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pgmpy.estimators import HillClimbSearch, BicScore, MaximumLikelihoodEstimator\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.estimators import BayesianEstimator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import entropy\n",
        "from tabulate import tabulate\n",
        "\n",
        "from tensorflow.keras import models, layers, regularizers, callbacks\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tJ_92Jl0KH_D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Network Data Generation 500, ..., 20000 Samples (sparse)"
      ],
      "metadata": {
        "id": "JGOSofbBKH_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o45qZNxH5zrS",
        "outputId": "00031f76-954d-47db-c68e-4a6d99250eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 50 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | medium     | good       | strong      | medium     | suburban    | 0.0527, 0.6158, 0.3315                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | low        | good       | weak        | low        | suburban    | 0.2405, 0.6238, 0.1357                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | good       | strong      | medium     | suburban    | 0.0527, 0.6158, 0.3315                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | medium     | poor       | moderate    | medium     | suburban    | 0.2731, 0.5101, 0.2168                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | medium     | average    | strong      | medium     | suburban    | 0.3413, 0.5824, 0.0764                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 100 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | low        | poor       | strong      | high       | rural       | 0.1620, 0.4029, 0.4351                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | high       | average    | moderate    | high       | rural       | 0.4446, 0.4356, 0.1198                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | high       | average    | weak        | high       | suburban    | 0.1929, 0.4481, 0.3590                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | low        | poor       | moderate    | medium     | suburban    | 0.3006, 0.3244, 0.3750                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | high       | average    | moderate    | low        | rural       | 0.3615, 0.2496, 0.3890                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 500 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | high       | poor       | moderate    | high       | suburban    | 0.3274, 0.4524, 0.2202                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | low        | average    | strong      | low        | urban       | 0.1132, 0.4190, 0.4678                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | low        | good       | weak        | low        | rural       | 0.0237, 0.2880, 0.6883                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | high       | average    | weak        | medium     | rural       | 0.1408, 0.5790, 0.2802                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | high       | good       | strong      | medium     | suburban    | 0.3325, 0.3373, 0.3303                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 1000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | low        | poor       | strong      | high       | urban       | 0.3217, 0.3682, 0.3102                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | high       | good       | strong      | medium     | suburban    | 0.4470, 0.1609, 0.3920                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | poor       | moderate    | medium     | suburban    | 0.2819, 0.4558, 0.2624                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | low        | good       | weak        | high       | urban       | 0.0067, 0.3749, 0.6183                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | low        | good       | weak        | high       | urban       | 0.0067, 0.3749, 0.6183                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 5000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | high       | poor       | strong      | high       | suburban    | 0.0010, 0.2017, 0.7973                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | medium     | good       | strong      | high       | urban       | 0.0661, 0.6418, 0.2921                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | poor       | moderate    | low        | urban       | 0.0489, 0.5417, 0.4093                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | medium     | good       | moderate    | high       | urban       | 0.2054, 0.6326, 0.1620                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | medium     | good       | moderate    | medium     | suburban    | 0.0454, 0.7416, 0.2130                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 10000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | medium     | poor       | weak        | low        | suburban    | 0.6323, 0.1415, 0.2262                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | medium     | good       | weak        | high       | rural       | 0.3305, 0.3150, 0.3545                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | average    | weak        | medium     | suburban    | 0.2255, 0.5359, 0.2386                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | high       | poor       | weak        | low        | suburban    | 0.3337, 0.2681, 0.3982                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | medium     | poor       | weak        | medium     | urban       | 0.0509, 0.9121, 0.0370                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 15000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | low        | good       | moderate    | high       | suburban    | 0.2513, 0.5449, 0.2039                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | low        | poor       | moderate    | high       | rural       | 0.1995, 0.3760, 0.4245                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | average    | moderate    | low        | rural       | 0.4375, 0.3944, 0.1681                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | low        | average    | moderate    | high       | rural       | 0.4545, 0.4513, 0.0942                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | high       | average    | strong      | medium     | suburban    | 0.3643, 0.6071, 0.0286                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 20000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | low        | average    | weak        | medium     | suburban    | 0.1408, 0.0646, 0.7946                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | low        | good       | weak        | low        | urban       | 0.4656, 0.3296, 0.2048                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | average    | strong      | high       | rural       | 0.3807, 0.3597, 0.2596                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | low        | average    | weak        | low        | suburban    | 0.1075, 0.4973, 0.3952                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | medium     | good       | weak        | medium     | rural       | 0.3852, 0.2413, 0.3735                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Generation and saving of individual samples complete for all sample sizes!\n"
          ]
        }
      ],
      "source": [
        "# Function to generate CPDs for the sparse structure with 5 nodes influencing SP\n",
        "def generate_cpds_sparse_5_total_nodes():\n",
        "    # Generate random probabilities for each of the 5 independent nodes\n",
        "    ir_probs = np.random.rand(3)\n",
        "    ir_probs /= ir_probs.sum()\n",
        "\n",
        "    ei_given_ir_probs = np.random.rand(3, 3)\n",
        "    ei_given_ir_probs /= ei_given_ir_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    irt_given_ir_probs = np.random.rand(3, 3)\n",
        "    irt_given_ir_probs /= irt_given_ir_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    ms_given_ir_probs = np.random.rand(3, 3)\n",
        "    ms_given_ir_probs /= ms_given_ir_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    geo_given_ir_probs = np.random.rand(3, 3)\n",
        "    geo_given_ir_probs /= geo_given_ir_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    # SP depends on the 5 other nodes without interactions between them\n",
        "    sp_probs = np.random.rand(3, 3, 3, 3, 3, 3)\n",
        "    sp_probs /= sp_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    return ir_probs, ei_given_ir_probs, irt_given_ir_probs, ms_given_ir_probs, geo_given_ir_probs, sp_probs\n",
        "\n",
        "# Function to generate and save samples with the sparse structure of 5 nodes total\n",
        "def generate_and_save_samples_sparse_5_total_nodes(ir_probs, ei_probs, irt_probs, ms_probs, geo_probs, sp_probs, sample_size, filename):\n",
        "    output_data = []\n",
        "\n",
        "    # Generate `sample_size` random samples\n",
        "    for _ in range(sample_size):\n",
        "        # Sample each of the 5 nodes individually\n",
        "        ir_state_idx = np.random.choice(3, p=ir_probs)\n",
        "        ir_state = ['low', 'medium', 'high'][ir_state_idx]\n",
        "\n",
        "        ei_probs_given_ir = ei_probs[:, ir_state_idx]\n",
        "        ei_state_idx = np.random.choice(3, p=ei_probs_given_ir)\n",
        "        ei_state = ['poor', 'average', 'good'][ei_state_idx]\n",
        "\n",
        "        irt_probs_given_ir = irt_probs[:, ir_state_idx]\n",
        "        irt_state_idx = np.random.choice(3, p=irt_probs_given_ir)\n",
        "        irt_state = ['weak', 'moderate', 'strong'][irt_state_idx]\n",
        "\n",
        "        ms_probs_given_ir = ms_probs[:, ir_state_idx]\n",
        "        ms_state_idx = np.random.choice(3, p=ms_probs_given_ir)\n",
        "        ms_state = ['low', 'medium', 'high'][ms_state_idx]\n",
        "\n",
        "        geo_probs_given_ir = geo_probs[:, ir_state_idx]\n",
        "        geo_state_idx = np.random.choice(3, p=geo_probs_given_ir)\n",
        "        geo_state = ['urban', 'suburban', 'rural'][geo_state_idx]\n",
        "\n",
        "        # Calculate SP probability based on the state of each node (sparse dependency on each)\n",
        "        sp_probs_given_all = sp_probs[:, ir_state_idx, ei_state_idx, irt_state_idx, ms_state_idx, geo_state_idx]\n",
        "        sp_state_idx = np.random.choice(3, p=sp_probs_given_all)\n",
        "        sp_state = ['decrease', 'stable', 'increase'][sp_state_idx]\n",
        "\n",
        "        # Append sample data to output list including probabilities for all nodes\n",
        "        output_data.append({\n",
        "            'IR_State': ir_state,\n",
        "            'EI_State': ei_state,\n",
        "            'IRT_State': irt_state,\n",
        "            'MS_State': ms_state,\n",
        "            'GEO_State': geo_state,\n",
        "            'SP_Probabilities (decrease, stable, increase)': ', '.join([f'{prob:.4f}' for prob in sp_probs_given_all]),\n",
        "            'Chosen_SP_State': sp_state\n",
        "        })\n",
        "\n",
        "    # Create a DataFrame from the output data\n",
        "    output_df = pd.DataFrame(output_data)\n",
        "\n",
        "    # Save the output DataFrame to a CSV file\n",
        "    output_df.to_csv(filename, index=False)\n",
        "\n",
        "    # Print the first few rows for visual confirmation\n",
        "    print(f\"\\nSample size: {sample_size} - First few rows of generated samples:\\n\")\n",
        "    print(tabulate(output_df.head(), headers='keys', tablefmt='grid'))\n",
        "\n",
        "# Generate and save samples for sample sizes\n",
        "sample_sizes = [50, 100, 500, 1000, 5000, 10000, 15000, 20000]\n",
        "\n",
        "for size in sample_sizes:\n",
        "    ir_probs, ei_probs, irt_probs, ms_probs, geo_probs, sp_probs = generate_cpds_sparse_5_total_nodes()\n",
        "    generate_and_save_samples_sparse_5_total_nodes(ir_probs, ei_probs, irt_probs, ms_probs, geo_probs, sp_probs, size, f'combined_probabilities_{size}.csv')\n",
        "\n",
        "print(\"\\nGeneration and saving of individual samples complete for all sample sizes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN & KL-Div"
      ],
      "metadata": {
        "id": "kzPGQCbLRikp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sizes to loop through\n",
        "sample_sizes = [50, 100, 500, 1000, 5000, 10000, 15000, 20000]\n",
        "# Define the Neural Network architecture with L2 regularization\n",
        "def create_nn_model(hidden_layers=1, nodes_per_layer=3, l2_lambda=0.01):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=(5,)))  # Updated input shape to include 5 features\n",
        "\n",
        "    # Hidden layers with L2 regularization and Dropout\n",
        "    for layer_num in range(hidden_layers):\n",
        "        model.add(layers.Dense(\n",
        "            nodes_per_layer,\n",
        "            activation='relu',\n",
        "            kernel_regularizer=regularizers.l2(l2_lambda),  # L2 regularization\n",
        "            name=f\"hidden_layer_{layer_num + 1}\"\n",
        "        ))\n",
        "        model.add(layers.Dropout(0.2))  # Dropout layer to reduce overfitting\n",
        "\n",
        "    # Output layer (3 classes: decrease, stable, increase) with L2 regularization\n",
        "    model.add(layers.Dense(\n",
        "        3,\n",
        "        activation='softmax',\n",
        "        kernel_regularizer=regularizers.l2(l2_lambda),\n",
        "        name=\"output_layer\"\n",
        "    ))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Prepare a dictionary to store extracted data for each sample size\n",
        "extracted_data = {}\n",
        "\n",
        "# Extract the required columns from all sample sizes first\n",
        "for size in sample_sizes:\n",
        "    outcomes_file = f'combined_probabilities_{size}.csv'\n",
        "    df = pd.read_csv(outcomes_file)\n",
        "\n",
        "    # Include new nodes in the required columns\n",
        "    required_columns = ['IR_State', 'EI_State', 'IRT_State', 'MS_State', 'GEO_State', 'Chosen_SP_State']\n",
        "    df_extracted = df[required_columns]\n",
        "\n",
        "    # Encode categorical variables for IR, EI, IRT, MS, GEO, and SP\n",
        "    ir_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "    ei_map = {'poor': 0, 'average': 1, 'good': 2}\n",
        "    irt_map = {'weak': 0, 'moderate': 1, 'strong': 2}\n",
        "    ms_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "    geo_map = {'urban': 0, 'suburban': 1, 'rural': 2}\n",
        "    sp_map = {'decrease': 0, 'stable': 1, 'increase': 2}\n",
        "\n",
        "    df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
        "    df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
        "    df_extracted['IRT_encoded'] = df_extracted['IRT_State'].map(irt_map)\n",
        "    df_extracted['MS_encoded'] = df_extracted['MS_State'].map(ms_map)\n",
        "    df_extracted['GEO_encoded'] = df_extracted['GEO_State'].map(geo_map)\n",
        "    df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
        "\n",
        "    extracted_data[size] = df_extracted\n",
        "\n",
        "# Initialize list to store K-L divergence and standard deviation results\n",
        "results = []\n",
        "epsilon = 1e-10  # Small value for smoothing\n",
        "\n",
        "for size in sample_sizes:\n",
        "    df = extracted_data[size]\n",
        "\n",
        "    # Features (IR, EI, IRT, MS, GEO) and labels (SP)\n",
        "    X = df[['IR_encoded', 'EI_encoded', 'IRT_encoded', 'MS_encoded', 'GEO_encoded']]\n",
        "    y = df['SP_encoded']\n",
        "\n",
        "    # Split into training, validation, and test sets\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Create and train the Neural Network model\n",
        "    nn_model = create_nn_model(hidden_layers=1, nodes_per_layer=3, l2_lambda=0.01)\n",
        "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    nn_model.fit(X_train, y_train, epochs=25, batch_size=16, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "    # Evaluate model accuracy\n",
        "    train_loss, train_accuracy = nn_model.evaluate(X_train, y_train, verbose=0)\n",
        "    val_loss, val_accuracy = nn_model.evaluate(X_val, y_val, verbose=0)\n",
        "    test_loss, test_accuracy = nn_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"\\nSample size: {size}\")\n",
        "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Predict on test data\n",
        "    predictions = nn_model.predict(X_test)\n",
        "    predicted_classes = predictions.argmax(axis=1)\n",
        "\n",
        "    # Calculate ground truth and predicted probabilities\n",
        "    ground_truth_probabilities = y_test.value_counts(normalize=True).sort_index()\n",
        "    predicted_probabilities = pd.Series(predicted_classes).value_counts(normalize=True).sort_index()\n",
        "\n",
        "    # Reindex both distributions and add smoothing\n",
        "    all_categories = sorted(set(ground_truth_probabilities.index).union(set(predicted_probabilities.index)))\n",
        "    ground_truth_probabilities = ground_truth_probabilities.reindex(all_categories, fill_value=epsilon)\n",
        "    predicted_probabilities = predicted_probabilities.reindex(all_categories, fill_value=epsilon)\n",
        "\n",
        "    # Calculate K-L divergence and standard deviation\n",
        "    kl_divergence = entropy(pk=ground_truth_probabilities, qk=predicted_probabilities)\n",
        "    std_dev = np.std(predicted_probabilities - ground_truth_probabilities)\n",
        "\n",
        "    results.append({\n",
        "        'Sample_Size': size,\n",
        "        'K-L_Divergence': kl_divergence,\n",
        "        'Standard_Deviation': std_dev\n",
        "    })\n",
        "\n",
        "    print(f\"K-L Divergence: {kl_divergence:.4f}\")\n",
        "    print(f\"Standard Deviation: {std_dev:.4f}\")\n",
        "\n",
        "    # Map integers back to the original SP labels\n",
        "    sp_reverse_map = ['decrease', 'stable', 'increase']\n",
        "    predicted_labels = [sp_reverse_map[label] for label in predicted_classes]\n",
        "\n",
        "    # Create DataFrame for displaying nodes, predicted SP, and chosen SP\n",
        "    result_df = pd.DataFrame({\n",
        "        'IR_State': df['IR_State'].iloc[X_test.index],\n",
        "        'EI_State': df['EI_State'].iloc[X_test.index],\n",
        "        'IRT_State': df['IRT_State'].iloc[X_test.index],\n",
        "        'MS_State': df['MS_State'].iloc[X_test.index],\n",
        "        'GEO_State': df['GEO_State'].iloc[X_test.index],\n",
        "        'Chosen_SP': df['Chosen_SP_State'].iloc[X_test.index],\n",
        "        'Predicted_SP': predicted_labels\n",
        "    })\n",
        "    print(f\"\\nPredicted Results for {size} samples (First 10 rows):\")\n",
        "    print(result_df.head(10))\n",
        "\n",
        "    # Save results for this sample size in a dedicated CSV\n",
        "    result_df.to_csv(f'test_results_{size}.csv', index=False)\n",
        "\n",
        "# Save only K-L and Standard Deviation results to a summary file\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('kl_std_results_summary.csv', index=False)\n",
        "\n",
        "print(\"\\nAll K-L divergence and standard deviation results have been saved in 'kl_std_results_summary.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8caooazSA-9B",
        "outputId": "d6f3e224-67a8-4578-e5fd-010459a4bd4f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 50\n",
            "Training Accuracy: 0.4571\n",
            "Validation Accuracy: 0.5714\n",
            "Test Accuracy: 0.2500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "K-L Divergence: 8.1443\n",
            "Standard Deviation: 0.3680\n",
            "\n",
            "Predicted Results for 50 samples (First 10 rows):\n",
            "   IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "19      low     poor  moderate   medium     rural    stable       stable\n",
            "4    medium  average    strong   medium  suburban    stable     decrease\n",
            "13   medium     good  moderate      low     rural  decrease       stable\n",
            "8       low     good  moderate   medium     rural  increase       stable\n",
            "48   medium     good  moderate      low     urban  decrease     decrease\n",
            "32   medium     poor  moderate   medium     urban  increase       stable\n",
            "30   medium     good    strong   medium  suburban  increase       stable\n",
            "39   medium     good  moderate   medium  suburban  decrease       stable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 100\n",
            "Training Accuracy: 0.2714\n",
            "Validation Accuracy: 0.4000\n",
            "Test Accuracy: 0.4000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "K-L Divergence: 4.6611\n",
            "Standard Deviation: 0.3810\n",
            "\n",
            "Predicted Results for 100 samples (First 10 rows):\n",
            "   IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "96     high     poor  moderate      low  suburban  decrease     decrease\n",
            "4      high  average  moderate      low     rural    stable     decrease\n",
            "42     high  average  moderate     high  suburban    stable     decrease\n",
            "77     high  average      weak   medium  suburban  decrease     decrease\n",
            "10     high     poor  moderate     high     rural  decrease     decrease\n",
            "0       low     poor    strong     high     rural  decrease     decrease\n",
            "9      high  average      weak   medium  suburban  decrease     decrease\n",
            "69     high  average  moderate     high     rural    stable     decrease\n",
            "73      low  average  moderate      low     rural  decrease     decrease\n",
            "83   medium  average    strong     high     urban  increase     decrease\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 500\n",
            "Training Accuracy: 0.3829\n",
            "Validation Accuracy: 0.4533\n",
            "Test Accuracy: 0.3467\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "K-L Divergence: 0.0149\n",
            "Standard Deviation: 0.0576\n",
            "\n",
            "Predicted Results for 500 samples (First 10 rows):\n",
            "    IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "290      low     good      weak     high     urban  increase     decrease\n",
            "316     high     poor  moderate   medium     urban    stable     decrease\n",
            "117     high     poor    strong      low  suburban  increase       stable\n",
            "455     high     good  moderate   medium     urban    stable     decrease\n",
            "268   medium     poor  moderate     high  suburban    stable     increase\n",
            "336     high     poor  moderate      low  suburban  increase       stable\n",
            "79       low  average      weak      low     rural  increase     increase\n",
            "208     high     good  moderate   medium  suburban  increase     decrease\n",
            "238   medium  average      weak   medium     rural  decrease       stable\n",
            "477     high     poor  moderate      low  suburban  increase       stable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 1000\n",
            "Training Accuracy: 0.4100\n",
            "Validation Accuracy: 0.4067\n",
            "Test Accuracy: 0.3200\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
            "K-L Divergence: 0.6502\n",
            "Standard Deviation: 0.3544\n",
            "\n",
            "Predicted Results for 1000 samples (First 10 rows):\n",
            "    IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "557   medium     poor  moderate   medium     urban    stable     increase\n",
            "798   medium     poor  moderate   medium     rural  increase     increase\n",
            "977      low     good      weak   medium     urban  increase     increase\n",
            "136      low  average    strong   medium     urban    stable     increase\n",
            "575   medium     good  moderate   medium     urban  decrease     increase\n",
            "544      low     good      weak      low     rural    stable     decrease\n",
            "332      low     good  moderate     high     urban    stable     increase\n",
            "917   medium     poor  moderate     high     urban  decrease     increase\n",
            "678   medium     poor  moderate   medium  suburban    stable     increase\n",
            "363      low     good    strong   medium     urban  increase     increase\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 5000\n",
            "Training Accuracy: 0.3831\n",
            "Validation Accuracy: 0.3680\n",
            "Test Accuracy: 0.3960\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "K-L Divergence: 12.8182\n",
            "Standard Deviation: 0.4272\n",
            "\n",
            "Predicted Results for 5000 samples (First 10 rows):\n",
            "     IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "790    medium     poor    strong      low  suburban  increase       stable\n",
            "2879   medium     poor    strong   medium     urban  decrease       stable\n",
            "2372   medium     poor    strong      low     urban  decrease       stable\n",
            "1351   medium     good    strong      low  suburban  decrease       stable\n",
            "3382      low     good  moderate   medium  suburban    stable       stable\n",
            "3433      low  average    strong      low  suburban  increase       stable\n",
            "1129   medium     good    strong      low  suburban  decrease       stable\n",
            "549    medium     poor  moderate      low  suburban  decrease       stable\n",
            "2835   medium     good  moderate      low  suburban  decrease       stable\n",
            "626       low  average  moderate      low  suburban  decrease       stable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 10000\n",
            "Training Accuracy: 0.3967\n",
            "Validation Accuracy: 0.3833\n",
            "Test Accuracy: 0.3840\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "K-L Divergence: 7.0338\n",
            "Standard Deviation: 0.2714\n",
            "\n",
            "Predicted Results for 10000 samples (First 10 rows):\n",
            "     IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "2697     high  average      weak      low     rural  increase     decrease\n",
            "6871   medium  average      weak     high     rural  decrease       stable\n",
            "3487     high     good  moderate   medium     rural  decrease       stable\n",
            "92       high     good    strong      low     rural    stable       stable\n",
            "9537   medium     poor      weak   medium     rural  decrease     decrease\n",
            "3205     high     poor      weak   medium  suburban    stable     decrease\n",
            "6641     high  average      weak   medium     rural  decrease     decrease\n",
            "8909     high  average  moderate     high     rural  increase       stable\n",
            "2884     high  average      weak     high     rural    stable       stable\n",
            "7173   medium     good    strong   medium  suburban  decrease       stable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 15000\n",
            "Training Accuracy: 0.3667\n",
            "Validation Accuracy: 0.3573\n",
            "Test Accuracy: 0.3773\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "K-L Divergence: 7.1294\n",
            "Standard Deviation: 0.3778\n",
            "\n",
            "Predicted Results for 15000 samples (First 10 rows):\n",
            "      IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "8602       low     good    strong   medium     rural  decrease       stable\n",
            "438        low     poor    strong     high  suburban  increase       stable\n",
            "8094      high     good    strong      low  suburban  increase       stable\n",
            "14355     high     good    strong   medium  suburban  increase       stable\n",
            "8581       low     good  moderate   medium  suburban    stable       stable\n",
            "12358      low     poor  moderate     high     rural  increase       stable\n",
            "511        low     good    strong     high     urban  increase       stable\n",
            "6594       low  average    strong     high     rural  increase       stable\n",
            "5245       low  average  moderate     high     rural    stable       stable\n",
            "5437       low     good  moderate   medium     rural  decrease       stable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 20000\n",
            "Training Accuracy: 0.3764\n",
            "Validation Accuracy: 0.3763\n",
            "Test Accuracy: 0.3657\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "K-L Divergence: 7.1880\n",
            "Standard Deviation: 0.3933\n",
            "\n",
            "Predicted Results for 20000 samples (First 10 rows):\n",
            "      IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "5348    medium  average      weak      low  suburban    stable     increase\n",
            "339     medium     good    strong     high     rural  increase     increase\n",
            "13591     high     good      weak     high     urban  increase     increase\n",
            "8153    medium     good      weak   medium     rural  increase     increase\n",
            "16345     high     poor  moderate   medium  suburban  decrease     increase\n",
            "16404      low     poor  moderate     high  suburban    stable     increase\n",
            "17185   medium  average    strong   medium     rural  increase     increase\n",
            "5709       low     good    strong   medium     rural  decrease     increase\n",
            "13020   medium     poor    strong   medium     rural    stable     increase\n",
            "7763    medium  average      weak     high  suburban  increase     increase\n",
            "\n",
            "All K-L divergence and standard deviation results have been saved in 'kl_std_results_summary.csv'.\n"
          ]
        }
      ]
    }
  ]
}