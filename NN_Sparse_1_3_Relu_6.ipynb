{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqSg6vHkKrIk0IvoE6n9zM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nonyeezeh/Research-Project-Code/blob/main/NN_Sparse_1_3_Relu_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "TxStpeNDKH_C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "86d15b8e-f826-4bb7-c025-8c252654bf67",
        "id": "RMbgaTihKH_D"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pgmpy in /usr/local/lib/python3.10/dist-packages (0.1.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.2.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.5.0+cu121)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.14.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy) (4.66.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.4.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.4.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.1.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.8.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai->pgmpy) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.16.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost->pgmpy) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->pgmpy) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->pgmpy) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->pgmpy) (4.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pgmpy) (1.16.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->pgmpy) (4.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai->pgmpy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai->pgmpy) (2.23.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai->pgmpy) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->pgmpy) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai->pgmpy) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install pgmpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pgmpy.estimators import HillClimbSearch, BicScore, MaximumLikelihoodEstimator\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.estimators import BayesianEstimator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import entropy\n",
        "from tabulate import tabulate\n",
        "\n",
        "from tensorflow.keras import models, layers, regularizers, callbacks\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tJ_92Jl0KH_D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Network Data Generation 500, ..., 20000 Samples (sparse)"
      ],
      "metadata": {
        "id": "JGOSofbBKH_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o45qZNxH5zrS",
        "outputId": "d304523a-eb6e-48ff-dd04-3d42ad65be89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 50 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | low        | average    | weak        | high       | urban       | 0.4110, 0.2860, 0.3030                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | low        | good       | moderate    | medium     | rural       | 0.3282, 0.6537, 0.0181                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | poor       | moderate    | low        | suburban    | 0.2408, 0.3330, 0.4262                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | low        | poor       | weak        | low        | suburban    | 0.1064, 0.6654, 0.2282                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | low        | good       | strong      | medium     | suburban    | 0.3676, 0.5350, 0.0975                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 100 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | high       | poor       | moderate    | medium     | urban       | 0.3139, 0.2908, 0.3953                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | high       | poor       | moderate    | medium     | suburban    | 0.4744, 0.2045, 0.3211                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | high       | good       | weak        | medium     | suburban    | 0.2187, 0.4898, 0.2915                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | low        | good       | moderate    | medium     | suburban    | 0.4180, 0.4285, 0.1535                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | high       | good       | strong      | medium     | rural       | 0.6568, 0.3383, 0.0049                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 500 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | medium     | good       | strong      | low        | urban       | 0.4433, 0.3832, 0.1735                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | low        | good       | strong      | medium     | suburban    | 0.4045, 0.1693, 0.4262                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | low        | good       | moderate    | low        | rural       | 0.5776, 0.1421, 0.2802                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | low        | poor       | moderate    | high       | urban       | 0.3362, 0.2354, 0.4284                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | medium     | poor       | moderate    | low        | rural       | 0.4130, 0.5170, 0.0700                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 1000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | medium     | average    | moderate    | low        | urban       | 0.3301, 0.3821, 0.2878                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | low        | good       | strong      | low        | urban       | 0.4856, 0.2616, 0.2528                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | low        | good       | strong      | high       | urban       | 0.4063, 0.2731, 0.3206                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | low        | average    | moderate    | high       | rural       | 0.1459, 0.5866, 0.2675                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | low        | good       | strong      | low        | suburban    | 0.5163, 0.0597, 0.4240                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 5000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | high       | average    | weak        | high       | rural       | 0.6901, 0.0602, 0.2497                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | low        | good       | moderate    | medium     | suburban    | 0.0620, 0.5238, 0.4142                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | medium     | poor       | moderate    | high       | suburban    | 0.0201, 0.5032, 0.4767                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | medium     | poor       | moderate    | medium     | suburban    | 0.1889, 0.3934, 0.4178                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | high       | good       | moderate    | medium     | rural       | 0.2460, 0.3360, 0.4180                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 10000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | low        | poor       | strong      | low        | urban       | 0.9441, 0.0063, 0.0496                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | high       | poor       | moderate    | low        | urban       | 0.4731, 0.0584, 0.4685                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | high       | poor       | strong      | medium     | suburban    | 0.2249, 0.1933, 0.5818                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | high       | poor       | moderate    | high       | urban       | 0.4057, 0.2101, 0.3842                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | high       | poor       | moderate    | high       | urban       | 0.4057, 0.2101, 0.3842                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 15000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | medium     | good       | moderate    | low        | suburban    | 0.0312, 0.4083, 0.5605                          | increase          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | high       | average    | moderate    | medium     | rural       | 0.2938, 0.4478, 0.2584                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | high       | average    | strong      | medium     | rural       | 0.0690, 0.7461, 0.1849                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | medium     | average    | strong      | medium     | rural       | 0.3088, 0.2312, 0.4600                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | high       | good       | weak        | low        | urban       | 0.3548, 0.4935, 0.1517                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Sample size: 20000 - First few rows of generated samples:\n",
            "\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|    | IR_State   | EI_State   | IRT_State   | MS_State   | GEO_State   | SP_Probabilities (decrease, stable, increase)   | Chosen_SP_State   |\n",
            "+====+============+============+=============+============+=============+=================================================+===================+\n",
            "|  0 | medium     | poor       | strong      | high       | rural       | 0.3021, 0.3850, 0.3129                          | decrease          |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  1 | high       | poor       | weak        | low        | urban       | 0.2338, 0.3957, 0.3705                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  2 | high       | good       | weak        | medium     | suburban    | 0.1724, 0.4134, 0.4143                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  3 | low        | average    | moderate    | medium     | rural       | 0.6882, 0.1493, 0.1625                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "|  4 | high       | good       | moderate    | medium     | urban       | 0.0708, 0.3744, 0.5548                          | stable            |\n",
            "+----+------------+------------+-------------+------------+-------------+-------------------------------------------------+-------------------+\n",
            "\n",
            "Generation and saving of individual samples complete for all sample sizes!\n"
          ]
        }
      ],
      "source": [
        "# Function to generate CPDs for the sparse structure with 6 nodes influencing SP\n",
        "def generate_cpds_sparse_6_total_nodes():\n",
        "    # Generate random probabilities for the independent nodes\n",
        "    ir_probs = np.random.rand(3)\n",
        "    ir_probs /= ir_probs.sum()\n",
        "\n",
        "    # Create diverse dependency structures for the nodes\n",
        "    ei_given_ir_probs = np.random.rand(3, 3)\n",
        "    ei_given_ir_probs /= ei_given_ir_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    irt_given_ei_probs = np.random.rand(3, 3)\n",
        "    irt_given_ei_probs /= irt_given_ei_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    ms_given_irt_probs = np.random.rand(3, 3)\n",
        "    ms_given_irt_probs /= ms_given_irt_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    geo_given_ms_probs = np.random.rand(3, 3)\n",
        "    geo_given_ms_probs /= geo_given_ms_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    # SP depends on the 6 nodes without interactions between them\n",
        "    sp_probs = np.random.rand(3, 3, 3, 3, 3, 3)\n",
        "    sp_probs /= sp_probs.sum(axis=0, keepdims=True)\n",
        "\n",
        "    return (ir_probs, ei_given_ir_probs, irt_given_ei_probs, ms_given_irt_probs, geo_given_ms_probs, sp_probs)\n",
        "\n",
        "# Function to generate and save samples with the sparse structure of 6 nodes total\n",
        "def generate_and_save_samples_sparse_6_total_nodes(ir_probs, ei_probs, irt_probs, ms_probs, geo_probs, sp_probs, sample_size, filename):\n",
        "    output_data = []\n",
        "\n",
        "    # Generate `sample_size` random samples\n",
        "    for _ in range(sample_size):\n",
        "        # Sample the independent node first\n",
        "        ir_state_idx = np.random.choice(3, p=ir_probs)\n",
        "        ir_state = ['low', 'medium', 'high'][ir_state_idx]\n",
        "\n",
        "        # Sample dependent nodes based on the new mixed dependency structure\n",
        "        ei_probs_given_ir = ei_probs[:, ir_state_idx]\n",
        "        ei_state_idx = np.random.choice(3, p=ei_probs_given_ir)\n",
        "        ei_state = ['poor', 'average', 'good'][ei_state_idx]\n",
        "\n",
        "        irt_probs_given_ei = irt_probs[:, ei_state_idx]\n",
        "        irt_state_idx = np.random.choice(3, p=irt_probs_given_ei)\n",
        "        irt_state = ['weak', 'moderate', 'strong'][irt_state_idx]\n",
        "\n",
        "        ms_probs_given_irt = ms_probs[:, irt_state_idx]\n",
        "        ms_state_idx = np.random.choice(3, p=ms_probs_given_irt)\n",
        "        ms_state = ['low', 'medium', 'high'][ms_state_idx]\n",
        "\n",
        "        geo_probs_given_ms = geo_probs[:, ms_state_idx]\n",
        "        geo_state_idx = np.random.choice(3, p=geo_probs_given_ms)\n",
        "        geo_state = ['urban', 'suburban', 'rural'][geo_state_idx]\n",
        "\n",
        "        # Calculate SP probability based on the state of each node (sparse dependency on each)\n",
        "        sp_probs_given_all = sp_probs[:, ir_state_idx, ei_state_idx, irt_state_idx, ms_state_idx, geo_state_idx]\n",
        "        sp_state_idx = np.random.choice(3, p=sp_probs_given_all)\n",
        "        sp_state = ['decrease', 'stable', 'increase'][sp_state_idx]\n",
        "\n",
        "        # Append sample data to output list including probabilities for all nodes\n",
        "        output_data.append({\n",
        "            'IR_State': ir_state,\n",
        "            'EI_State': ei_state,\n",
        "            'IRT_State': irt_state,\n",
        "            'MS_State': ms_state,\n",
        "            'GEO_State': geo_state,\n",
        "            'SP_Probabilities (decrease, stable, increase)': ', '.join([f'{prob:.4f}' for prob in sp_probs_given_all]),\n",
        "            'Chosen_SP_State': sp_state\n",
        "        })\n",
        "\n",
        "    # Create a DataFrame from the output data\n",
        "    output_df = pd.DataFrame(output_data)\n",
        "\n",
        "    # Save the output DataFrame to a CSV file\n",
        "    output_df.to_csv(filename, index=False)\n",
        "\n",
        "    # Print the first few rows for visual confirmation\n",
        "    print(f\"\\nSample size: {sample_size} - First few rows of generated samples:\\n\")\n",
        "    print(tabulate(output_df.head(), headers='keys', tablefmt='grid'))\n",
        "\n",
        "# Generate and save samples for sample sizes\n",
        "sample_sizes = [50, 100, 500, 1000, 5000, 10000, 15000, 20000]\n",
        "\n",
        "for size in sample_sizes:\n",
        "    (ir_probs, ei_probs, irt_probs, ms_probs, geo_probs, sp_probs) = generate_cpds_sparse_6_total_nodes()\n",
        "    generate_and_save_samples_sparse_6_total_nodes(ir_probs, ei_probs, irt_probs, ms_probs, geo_probs, sp_probs, size, f'combined_probabilities_{size}.csv')\n",
        "\n",
        "print(\"\\nGeneration and saving of individual samples complete for all sample sizes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN & KL-Div"
      ],
      "metadata": {
        "id": "kzPGQCbLRikp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sizes to loop through\n",
        "sample_sizes = [50, 100, 500, 1000, 5000, 10000, 15000, 20000]\n",
        "# Define the Neural Network architecture with L2 regularization\n",
        "def create_nn_model(hidden_layers=1, nodes_per_layer=3, l2_lambda=0.01):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=(5,)))  # Updated input shape to include 5 features\n",
        "\n",
        "    # Hidden layers with L2 regularization and Dropout\n",
        "    for layer_num in range(hidden_layers):\n",
        "        model.add(layers.Dense(\n",
        "            nodes_per_layer,\n",
        "            activation='relu',\n",
        "            kernel_regularizer=regularizers.l2(l2_lambda),  # L2 regularization\n",
        "            name=f\"hidden_layer_{layer_num + 1}\"\n",
        "        ))\n",
        "        model.add(layers.Dropout(0.2))  # Dropout layer to reduce overfitting\n",
        "\n",
        "    # Output layer (3 classes: decrease, stable, increase) with L2 regularization\n",
        "    model.add(layers.Dense(\n",
        "        3,\n",
        "        activation='softmax',\n",
        "        kernel_regularizer=regularizers.l2(l2_lambda),\n",
        "        name=\"output_layer\"\n",
        "    ))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Prepare a dictionary to store extracted data for each sample size\n",
        "extracted_data = {}\n",
        "\n",
        "# Extract the required columns from all sample sizes first\n",
        "for size in sample_sizes:\n",
        "    outcomes_file = f'combined_probabilities_{size}.csv'\n",
        "    df = pd.read_csv(outcomes_file)\n",
        "\n",
        "    # Include new nodes in the required columns\n",
        "    required_columns = ['IR_State', 'EI_State', 'IRT_State', 'MS_State', 'GEO_State','Chosen_SP_State']\n",
        "    df_extracted = df[required_columns]\n",
        "\n",
        "    # Encode categorical variables for IR, EI, IRT, MS, GEO, and SP\n",
        "    ir_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "    ei_map = {'poor': 0, 'average': 1, 'good': 2}\n",
        "    irt_map = {'weak': 0, 'moderate': 1, 'strong': 2}\n",
        "    ms_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "    geo_map = {'urban': 0, 'suburban': 1, 'rural': 2}\n",
        "    sp_map = {'decrease': 0, 'stable': 1, 'increase': 2}\n",
        "\n",
        "    df_extracted['IR_encoded'] = df_extracted['IR_State'].map(ir_map)\n",
        "    df_extracted['EI_encoded'] = df_extracted['EI_State'].map(ei_map)\n",
        "    df_extracted['IRT_encoded'] = df_extracted['IRT_State'].map(irt_map)\n",
        "    df_extracted['MS_encoded'] = df_extracted['MS_State'].map(ms_map)\n",
        "    df_extracted['GEO_encoded'] = df_extracted['GEO_State'].map(geo_map)\n",
        "    df_extracted['SP_encoded'] = df_extracted['Chosen_SP_State'].map(sp_map)\n",
        "\n",
        "    extracted_data[size] = df_extracted\n",
        "\n",
        "# Initialize list to store K-L divergence and standard deviation results\n",
        "results = []\n",
        "epsilon = 1e-10  # Small value for smoothing\n",
        "\n",
        "for size in sample_sizes:\n",
        "    df = extracted_data[size]\n",
        "\n",
        "    # Features (IR, EI, IRT, MS, GEO) and labels (SP)\n",
        "    X = df[['IR_encoded', 'EI_encoded', 'IRT_encoded', 'MS_encoded', 'GEO_encoded']]\n",
        "    y = df['SP_encoded']\n",
        "\n",
        "    # Split into training, validation, and test sets\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Create and train the Neural Network model\n",
        "    nn_model = create_nn_model(hidden_layers=1, nodes_per_layer=3, l2_lambda=0.01)\n",
        "    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    nn_model.fit(X_train, y_train, epochs=25, batch_size=16, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "    # Evaluate model accuracy\n",
        "    train_loss, train_accuracy = nn_model.evaluate(X_train, y_train, verbose=0)\n",
        "    val_loss, val_accuracy = nn_model.evaluate(X_val, y_val, verbose=0)\n",
        "    test_loss, test_accuracy = nn_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"\\nSample size: {size}\")\n",
        "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Predict on test data\n",
        "    predictions = nn_model.predict(X_test)\n",
        "    predicted_classes = predictions.argmax(axis=1)\n",
        "\n",
        "    # Calculate ground truth and predicted probabilities\n",
        "    ground_truth_probabilities = y_test.value_counts(normalize=True).sort_index()\n",
        "    predicted_probabilities = pd.Series(predicted_classes).value_counts(normalize=True).sort_index()\n",
        "\n",
        "    # Reindex both distributions and add smoothing\n",
        "    all_categories = sorted(set(ground_truth_probabilities.index).union(set(predicted_probabilities.index)))\n",
        "    ground_truth_probabilities = ground_truth_probabilities.reindex(all_categories, fill_value=epsilon)\n",
        "    predicted_probabilities = predicted_probabilities.reindex(all_categories, fill_value=epsilon)\n",
        "\n",
        "    # Calculate K-L divergence and standard deviation\n",
        "    kl_divergence = entropy(pk=ground_truth_probabilities, qk=predicted_probabilities)\n",
        "    std_dev = np.std(predicted_probabilities - ground_truth_probabilities)\n",
        "\n",
        "    results.append({\n",
        "        'Sample_Size': size,\n",
        "        'K-L_Divergence': kl_divergence,\n",
        "        'Standard_Deviation': std_dev\n",
        "    })\n",
        "\n",
        "    print(f\"K-L Divergence: {kl_divergence:.4f}\")\n",
        "    print(f\"Standard Deviation: {std_dev:.4f}\")\n",
        "\n",
        "    # Map integers back to the original SP labels\n",
        "    sp_reverse_map = ['decrease', 'stable', 'increase']\n",
        "    predicted_labels = [sp_reverse_map[label] for label in predicted_classes]\n",
        "\n",
        "    # Create DataFrame for displaying nodes, predicted SP, and chosen SP\n",
        "    result_df = pd.DataFrame({\n",
        "        'IR_State': df['IR_State'].iloc[X_test.index],\n",
        "        'EI_State': df['EI_State'].iloc[X_test.index],\n",
        "        'IRT_State': df['IRT_State'].iloc[X_test.index],\n",
        "        'MS_State': df['MS_State'].iloc[X_test.index],\n",
        "        'GEO_State': df['GEO_State'].iloc[X_test.index],\n",
        "        'Chosen_SP': df['Chosen_SP_State'].iloc[X_test.index],\n",
        "        'Predicted_SP': predicted_labels\n",
        "    })\n",
        "    print(f\"\\nPredicted Results for {size} samples (First 10 rows):\")\n",
        "    print(result_df.head(10))\n",
        "\n",
        "    # Save results for this sample size in a dedicated CSV\n",
        "    result_df.to_csv(f'test_results_{size}.csv', index=False)\n",
        "\n",
        "# Save only K-L and Standard Deviation results to a summary file\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('kl_std_results_summary.csv', index=False)\n",
        "\n",
        "print(\"\\nAll K-L divergence and standard deviation results have been saved in 'kl_std_results_summary.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8caooazSA-9B",
        "outputId": "68793e10-9714-46a0-a04f-eac503ec186e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 50\n",
            "Training Accuracy: 0.2571\n",
            "Validation Accuracy: 0.4286\n",
            "Test Accuracy: 0.2500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "K-L Divergence: 2.9163\n",
            "Standard Deviation: 0.3680\n",
            "\n",
            "Predicted Results for 50 samples (First 10 rows):\n",
            "   IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "19     high     good  moderate      low     urban  decrease       stable\n",
            "4       low     good    strong   medium  suburban  decrease       stable\n",
            "13      low  average    strong   medium     rural  decrease       stable\n",
            "8    medium     good  moderate      low     urban  decrease       stable\n",
            "48      low     poor    strong      low  suburban    stable     decrease\n",
            "32      low     poor  moderate     high     urban  decrease     decrease\n",
            "30      low     good      weak      low  suburban  increase       stable\n",
            "39      low  average      weak      low  suburban    stable       stable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 100\n",
            "Training Accuracy: 0.2286\n",
            "Validation Accuracy: 0.3333\n",
            "Test Accuracy: 0.3333\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "K-L Divergence: 5.0582\n",
            "Standard Deviation: 0.4838\n",
            "\n",
            "Predicted Results for 100 samples (First 10 rows):\n",
            "   IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "96     high     good  moderate     high     urban  decrease     increase\n",
            "4      high     good    strong   medium     rural    stable     increase\n",
            "42     high     good  moderate     high     urban  decrease     increase\n",
            "77     high     good    strong     high     rural  decrease     increase\n",
            "10     high     good    strong      low     urban    stable     increase\n",
            "0      high     poor  moderate   medium     urban    stable     increase\n",
            "9      high     good  moderate   medium  suburban    stable     increase\n",
            "69   medium  average    strong     high     urban    stable     increase\n",
            "73      low     poor    strong   medium     rural  increase     increase\n",
            "83   medium     poor  moderate   medium  suburban  increase     increase\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 500\n",
            "Training Accuracy: 0.2886\n",
            "Validation Accuracy: 0.3200\n",
            "Test Accuracy: 0.2933\n",
            "\r\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bd2fd798b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "K-L Divergence: 0.0692\n",
            "Standard Deviation: 0.1147\n",
            "\n",
            "Predicted Results for 500 samples (First 10 rows):\n",
            "    IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "290      low  average    strong      low     rural  increase       stable\n",
            "316   medium     poor  moderate      low     rural    stable     decrease\n",
            "117      low  average      weak      low     rural  increase     decrease\n",
            "455      low  average    strong   medium     rural  increase       stable\n",
            "268   medium     poor    strong      low     urban  increase     increase\n",
            "336      low     good    strong   medium     urban    stable     increase\n",
            "79    medium     poor  moderate   medium     rural    stable     decrease\n",
            "208      low     good  moderate      low  suburban  decrease       stable\n",
            "238      low     poor    strong   medium  suburban  decrease     decrease\n",
            "477      low     good    strong      low     rural    stable       stable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bd31055e8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 1000\n",
            "Training Accuracy: 0.3643\n",
            "Validation Accuracy: 0.3000\n",
            "Test Accuracy: 0.3533\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-L Divergence: 0.5729\n",
            "Standard Deviation: 0.2151\n",
            "\n",
            "Predicted Results for 1000 samples (First 10 rows):\n",
            "    IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "557      low     good    strong   medium  suburban  decrease     decrease\n",
            "798      low     poor    strong     high     rural    stable     increase\n",
            "977      low     poor    strong     high     urban    stable     increase\n",
            "136   medium     good    strong   medium     rural  decrease     increase\n",
            "575      low     poor      weak      low     urban    stable     decrease\n",
            "544      low  average    strong   medium  suburban  increase     increase\n",
            "332      low  average      weak      low     rural  increase     decrease\n",
            "917      low     good    strong   medium  suburban    stable     decrease\n",
            "678      low     good    strong   medium     rural  increase     increase\n",
            "363   medium  average    strong     high     urban    stable     increase\n",
            "\n",
            "Sample size: 5000\n",
            "Training Accuracy: 0.3466\n",
            "Validation Accuracy: 0.3707\n",
            "Test Accuracy: 0.3187\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "K-L Divergence: 7.5030\n",
            "Standard Deviation: 0.3669\n",
            "\n",
            "Predicted Results for 5000 samples (First 10 rows):\n",
            "     IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "790      high     good  moderate      low     rural  decrease     increase\n",
            "2879   medium     good    strong   medium     rural  increase       stable\n",
            "2372   medium     good    strong      low     rural    stable     increase\n",
            "1351     high     good  moderate      low     urban    stable     increase\n",
            "3382   medium     good  moderate   medium     urban  decrease     increase\n",
            "3433      low     good  moderate   medium  suburban    stable     increase\n",
            "1129      low     good  moderate   medium  suburban    stable     increase\n",
            "549      high     good      weak   medium     rural  decrease     increase\n",
            "2835     high  average    strong   medium     rural    stable       stable\n",
            "626       low     good      weak      low     urban  decrease     increase\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 10000\n",
            "Training Accuracy: 0.3911\n",
            "Validation Accuracy: 0.3907\n",
            "Test Accuracy: 0.3747\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "K-L Divergence: 13.3051\n",
            "Standard Deviation: 0.4424\n",
            "\n",
            "Predicted Results for 10000 samples (First 10 rows):\n",
            "     IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "2697   medium     poor    strong      low     urban  decrease     decrease\n",
            "6871      low  average  moderate      low  suburban  increase     decrease\n",
            "3487      low     good  moderate      low     urban  decrease     decrease\n",
            "92        low     good  moderate      low     rural  decrease     decrease\n",
            "9537     high     poor    strong   medium     rural    stable     decrease\n",
            "3205   medium  average  moderate      low     urban  increase     decrease\n",
            "6641      low     poor  moderate      low  suburban  increase     decrease\n",
            "8909   medium     good  moderate      low     urban    stable     decrease\n",
            "2884      low     poor    strong   medium     rural    stable     decrease\n",
            "7173      low     poor  moderate      low     urban    stable     decrease\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 15000\n",
            "Training Accuracy: 0.3785\n",
            "Validation Accuracy: 0.4022\n",
            "Test Accuracy: 0.3716\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "K-L Divergence: 0.5317\n",
            "Standard Deviation: 0.2654\n",
            "\n",
            "Predicted Results for 15000 samples (First 10 rows):\n",
            "      IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "8602      high     good      weak      low     urban  decrease       stable\n",
            "438       high     good      weak   medium     rural  decrease       stable\n",
            "8094      high     good      weak      low     rural    stable       stable\n",
            "14355   medium     poor      weak   medium  suburban  increase       stable\n",
            "8581      high     good      weak   medium     rural    stable       stable\n",
            "12358   medium     poor  moderate   medium  suburban  increase     increase\n",
            "511       high  average    strong      low     urban  increase     increase\n",
            "6594    medium  average    strong      low     urban    stable     increase\n",
            "5245    medium  average  moderate      low     rural    stable       stable\n",
            "5437    medium  average      weak      low  suburban  decrease       stable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample size: 20000\n",
            "Training Accuracy: 0.3971\n",
            "Validation Accuracy: 0.4030\n",
            "Test Accuracy: 0.3947\n",
            "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "K-L Divergence: 6.0782\n",
            "Standard Deviation: 0.2132\n",
            "\n",
            "Predicted Results for 20000 samples (First 10 rows):\n",
            "      IR_State EI_State IRT_State MS_State GEO_State Chosen_SP Predicted_SP\n",
            "5348      high     good  moderate     high     rural  decrease     increase\n",
            "339     medium  average    strong   medium     urban  increase     decrease\n",
            "13591     high     good      weak     high     urban    stable     increase\n",
            "8153       low     poor      weak      low     rural  increase     decrease\n",
            "16345     high     good  moderate      low  suburban  increase     increase\n",
            "16404     high     good  moderate     high     urban  decrease     increase\n",
            "17185   medium  average  moderate   medium  suburban    stable     decrease\n",
            "5709      high     good  moderate   medium  suburban  increase     increase\n",
            "13020      low     poor      weak      low  suburban  decrease     decrease\n",
            "7763       low  average    strong     high     rural  decrease     decrease\n",
            "\n",
            "All K-L divergence and standard deviation results have been saved in 'kl_std_results_summary.csv'.\n"
          ]
        }
      ]
    }
  ]
}